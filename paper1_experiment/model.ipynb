{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check gpu device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>poi_id</th>\n",
       "      <th>poi_category_id</th>\n",
       "      <th>poi_category_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>time_offset</th>\n",
       "      <th>UTC_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>470</td>\n",
       "      <td>49bbd6c0f964a520f4531fe3</td>\n",
       "      <td>4bf58dd8d48988d127951735</td>\n",
       "      <td>Arts &amp; Crafts Store</td>\n",
       "      <td>40.719810</td>\n",
       "      <td>-74.002581</td>\n",
       "      <td>-240</td>\n",
       "      <td>Tue Apr 03 18:00:09 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>979</td>\n",
       "      <td>4a43c0aef964a520c6a61fe3</td>\n",
       "      <td>4bf58dd8d48988d1df941735</td>\n",
       "      <td>Bridge</td>\n",
       "      <td>40.606800</td>\n",
       "      <td>-74.044170</td>\n",
       "      <td>-240</td>\n",
       "      <td>Tue Apr 03 18:00:25 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69</td>\n",
       "      <td>4c5cc7b485a1e21e00d35711</td>\n",
       "      <td>4bf58dd8d48988d103941735</td>\n",
       "      <td>Home (private)</td>\n",
       "      <td>40.716162</td>\n",
       "      <td>-73.883070</td>\n",
       "      <td>-240</td>\n",
       "      <td>Tue Apr 03 18:02:24 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>395</td>\n",
       "      <td>4bc7086715a7ef3bef9878da</td>\n",
       "      <td>4bf58dd8d48988d104941735</td>\n",
       "      <td>Medical Center</td>\n",
       "      <td>40.745164</td>\n",
       "      <td>-73.982519</td>\n",
       "      <td>-240</td>\n",
       "      <td>Tue Apr 03 18:02:41 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87</td>\n",
       "      <td>4cf2c5321d18a143951b5cec</td>\n",
       "      <td>4bf58dd8d48988d1cb941735</td>\n",
       "      <td>Food Truck</td>\n",
       "      <td>40.740104</td>\n",
       "      <td>-73.989658</td>\n",
       "      <td>-240</td>\n",
       "      <td>Tue Apr 03 18:03:00 +0000 2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                    poi_id           poi_category_id  \\\n",
       "0      470  49bbd6c0f964a520f4531fe3  4bf58dd8d48988d127951735   \n",
       "1      979  4a43c0aef964a520c6a61fe3  4bf58dd8d48988d1df941735   \n",
       "2       69  4c5cc7b485a1e21e00d35711  4bf58dd8d48988d103941735   \n",
       "3      395  4bc7086715a7ef3bef9878da  4bf58dd8d48988d104941735   \n",
       "4       87  4cf2c5321d18a143951b5cec  4bf58dd8d48988d1cb941735   \n",
       "\n",
       "     poi_category_name   latitude  longitude  time_offset  \\\n",
       "0  Arts & Crafts Store  40.719810 -74.002581         -240   \n",
       "1               Bridge  40.606800 -74.044170         -240   \n",
       "2       Home (private)  40.716162 -73.883070         -240   \n",
       "3       Medical Center  40.745164 -73.982519         -240   \n",
       "4           Food Truck  40.740104 -73.989658         -240   \n",
       "\n",
       "                         UTC_time  \n",
       "0  Tue Apr 03 18:00:09 +0000 2012  \n",
       "1  Tue Apr 03 18:00:25 +0000 2012  \n",
       "2  Tue Apr 03 18:02:24 +0000 2012  \n",
       "3  Tue Apr 03 18:02:41 +0000 2012  \n",
       "4  Tue Apr 03 18:03:00 +0000 2012  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "dir = 'E:\\\\Sebnewrepo\\\\Data\\\\checkin_data\\\\dataset_tsmc2014/'\n",
    "checkin_file = 'dataset_TSMC2014_NYC.txt'\n",
    "col = ['user_id',\n",
    "       'poi_id',\n",
    "       'poi_category_id',\n",
    "       'poi_category_name',\n",
    "       'latitude', \n",
    "       'longitude',\n",
    "       'time_offset',\n",
    "       'UTC_time']\n",
    "df = pd.read_csv(dir + checkin_file, delimiter = \"\\t\", names = col)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users with < 5 interactoins are removed\n",
      "POIs with < 5 interactoins are removed\n",
      "num of users:1083, num of POIs:9989\n"
     ]
    }
   ],
   "source": [
    "# remove infrequent items and users\n",
    "from copy import deepcopy\n",
    "def rm_infrequent_items(data, min_counts):\n",
    "    df = deepcopy(data)\n",
    "    counts = df['poi_id'].value_counts()\n",
    "    df = df[df['poi_id'].isin(counts[counts >= min_counts].index)]\n",
    "    print(\"POIs with < {} interactoins are removed\".format(min_counts))\n",
    "    return df\n",
    "def rm_infrequent_users(data, min_counts):\n",
    "    df = deepcopy(data)\n",
    "    counts = df['user_id'].value_counts()\n",
    "    df = df[df[\"user_id\"].isin(counts[counts >= min_counts].index)]\n",
    "    print(\"users with < {} interactoins are removed\".format(min_counts))\n",
    "    return df\n",
    "          \n",
    "filtered_df = rm_infrequent_users(df, 5)\n",
    "filtered_df = rm_infrequent_items(filtered_df, 5)\n",
    "print('num of users:{}, num of POIs:{}'.format(len(filtered_df['user_id'].unique()), len(filtered_df['poi_id'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>poi_category_id</th>\n",
       "      <th>poi_category_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>time_offset</th>\n",
       "      <th>UTC_time</th>\n",
       "      <th>poi_encode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>470</td>\n",
       "      <td>4bf58dd8d48988d127951735</td>\n",
       "      <td>Arts &amp; Crafts Store</td>\n",
       "      <td>40.719810</td>\n",
       "      <td>-74.002581</td>\n",
       "      <td>-240</td>\n",
       "      <td>Tue Apr 03 18:00:09 +0000 2012</td>\n",
       "      <td>1230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>979</td>\n",
       "      <td>4bf58dd8d48988d1df941735</td>\n",
       "      <td>Bridge</td>\n",
       "      <td>40.606800</td>\n",
       "      <td>-74.044170</td>\n",
       "      <td>-240</td>\n",
       "      <td>Tue Apr 03 18:00:25 +0000 2012</td>\n",
       "      <td>1879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69</td>\n",
       "      <td>4bf58dd8d48988d103941735</td>\n",
       "      <td>Home (private)</td>\n",
       "      <td>40.716162</td>\n",
       "      <td>-73.883070</td>\n",
       "      <td>-240</td>\n",
       "      <td>Tue Apr 03 18:02:24 +0000 2012</td>\n",
       "      <td>6161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87</td>\n",
       "      <td>4bf58dd8d48988d1cb941735</td>\n",
       "      <td>Food Truck</td>\n",
       "      <td>40.740104</td>\n",
       "      <td>-73.989658</td>\n",
       "      <td>-240</td>\n",
       "      <td>Tue Apr 03 18:03:00 +0000 2012</td>\n",
       "      <td>6859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>484</td>\n",
       "      <td>4bf58dd8d48988d118951735</td>\n",
       "      <td>Food &amp; Drink Shop</td>\n",
       "      <td>40.690427</td>\n",
       "      <td>-73.954687</td>\n",
       "      <td>-240</td>\n",
       "      <td>Tue Apr 03 18:04:00 +0000 2012</td>\n",
       "      <td>4017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id           poi_category_id    poi_category_name   latitude  \\\n",
       "0      470  4bf58dd8d48988d127951735  Arts & Crafts Store  40.719810   \n",
       "1      979  4bf58dd8d48988d1df941735               Bridge  40.606800   \n",
       "2       69  4bf58dd8d48988d103941735       Home (private)  40.716162   \n",
       "4       87  4bf58dd8d48988d1cb941735           Food Truck  40.740104   \n",
       "5      484  4bf58dd8d48988d118951735    Food & Drink Shop  40.690427   \n",
       "\n",
       "   longitude  time_offset                        UTC_time  poi_encode  \n",
       "0 -74.002581         -240  Tue Apr 03 18:00:09 +0000 2012        1230  \n",
       "1 -74.044170         -240  Tue Apr 03 18:00:25 +0000 2012        1879  \n",
       "2 -73.883070         -240  Tue Apr 03 18:02:24 +0000 2012        6161  \n",
       "4 -73.989658         -240  Tue Apr 03 18:03:00 +0000 2012        6859  \n",
       "5 -73.954687         -240  Tue Apr 03 18:04:00 +0000 2012        4017  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POIs encode, and generate encode mapping\n",
    "poi_cat = pd.Categorical(filtered_df['poi_id'])\n",
    "poi_encode = poi_cat.codes\n",
    "#generate poi mapping table\n",
    "poi_mapping = pd.DataFrame({\n",
    "    'poi_encode': poi_encode,\n",
    "    'poi_id': filtered_df['poi_id']\n",
    "    })\n",
    "#drop duplicate\n",
    "poi_mapping_output = poi_mapping.drop_duplicates()\n",
    "filtered_df['poi_encode'] = poi_encode\n",
    "filtered_df.drop(['poi_id'], axis = 1, inplace = True)\n",
    "filtered_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to sequential data per user\n",
    "df_ordered = filtered_df.groupby('user_id').apply(pd.DataFrame.sort_values, 'UTC_time')\n",
    "df_input = pd.DataFrame({\n",
    "    'user_id': df_ordered['user_id'] - 1,  # user_id offset by 1\n",
    "    'poi_id': df_ordered['poi_encode'],\n",
    "    #'implicit': np.ones(179468)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>poi_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179463</th>\n",
       "      <td>1082</td>\n",
       "      <td>1956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179464</th>\n",
       "      <td>1082</td>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179465</th>\n",
       "      <td>1082</td>\n",
       "      <td>8703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179466</th>\n",
       "      <td>1082</td>\n",
       "      <td>1956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179467</th>\n",
       "      <td>1082</td>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179468 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  poi_id\n",
       "0             0    9066\n",
       "1             0     405\n",
       "2             0     773\n",
       "3             0     678\n",
       "4             0     499\n",
       "...         ...     ...\n",
       "179463     1082    1956\n",
       "179464     1082     672\n",
       "179465     1082    8703\n",
       "179466     1082    1956\n",
       "179467     1082     672\n",
       "\n",
       "[179468 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input = df_input.reset_index(drop = True)\n",
    "df_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_sample_item(num_item, neg_num,item_list):\n",
    "    neg_list = []\n",
    "    while len(neg_list)<neg_num:\n",
    "        neg_item = np.random.choice(num_item, 1)[0]\n",
    "        while neg_item in item_list:\n",
    "            neg_item = np.random.choice(num_item, 1)[0]\n",
    "        neg_list.append(neg_item)\n",
    "    return neg_list\n",
    "\n",
    "def generate_train_test_data(data, neg_num):\n",
    "    # user rating item\n",
    "    num_item = len(data['poi_id'].unique())\n",
    "    \n",
    "    train = []\n",
    "    test = []\n",
    "    # split data\n",
    "    for uid in data['user_id'].unique():\n",
    "        item_list = data[data['user_id']==uid]['poi_id'].tolist()\n",
    "        for i in range(len(item_list)-8):\n",
    "            item_seq = item_list[i:i+8]\n",
    "            if i == len(item_list)-9:\n",
    "                neg_list = neg_sample_item(num_item, neg_num,item_list)\n",
    "                result_slice = [uid] + item_seq + neg_list\n",
    "                test.append(result_slice)\n",
    "            else:\n",
    "                neg_list = neg_sample_item(num_item, neg_num,item_list)\n",
    "                result_slice = [uid] + item_seq + neg_list\n",
    "                train.append(result_slice)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_data, test_data = generate_train_test_data(df_input, 3)\n",
    "\n",
    "train_data = torch.from_numpy(np.array(train_data))\n",
    "test_data = torch.from_numpy(np.array(test_data))\n",
    "train_x = train_data[:,:6]\n",
    "train_y = train_data[:,6:]\n",
    "\n",
    "# construct dataset for train test\n",
    "train_dataset = TensorDataset(train_x, train_y)\n",
    "dataloader = DataLoader(dataset=train_dataset, batch_size=512, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### self att Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(nn.Module):\n",
    "    def __init__(self, num_user, num_item, L, w, embedding_dim, device):\n",
    "        \n",
    "        super(model, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_user = num_user\n",
    "        self.num_item = num_item\n",
    "        self.L = L  # sequence length\n",
    "        self.w = w  # learnable para\n",
    "        \n",
    "        # define embedding\n",
    "        \n",
    "        self.user_embed = nn.Embedding(num_user, embedding_dim).to(device)\n",
    "        self.item_embed = nn.Embedding(num_item, embedding_dim).to(device)\n",
    "        self.linear1 = nn.Linear(embedding_dim, embedding_dim).to(device)\n",
    "        print(self.linear1)\n",
    "        self.item_position_embed = nn.Embedding.from_pretrained(self.position_embed(L),freeze=True)\n",
    "        \n",
    "        # initialize\n",
    "        self.user_embed.weight.data.normal_(0, 1.0/self.user_embed.embedding_dim)\n",
    "        self.item_embed.weight.data.normal_(0, 1.0/self.item_embed.embedding_dim)\n",
    "        self.linear1.weight.data.normal_(mean=0, std=np.sqrt(2.0 / embedding_dim))\n",
    "    \n",
    "    def position_embed(self, L):\n",
    "        position_embedding = np.array([[pos/np.power(1000, 2.*i)/ self.embedding_dim for i in range(self.embedding_dim)]\n",
    "                                      for pos in range(L)])\n",
    "        position_embedding[:,0::2] = np.sin(position_embedding[:,0::2])\n",
    "        position_embedding[:,1::2] = np.cos(position_embedding[:,1::2])\n",
    "        t = torch.from_numpy(position_embedding).to(device)\n",
    "        return t\n",
    "    \n",
    "    def forward(self, user_id, seq_item, target = None, for_pred = False):\n",
    "        \n",
    "        '''\n",
    "        user_id\n",
    "        seq_item = L item id that user interact before\n",
    "        target: item target\n",
    "        '''\n",
    "        \n",
    "        # sequential item embedding\n",
    "        seq_item = seq_item.to(device)\n",
    "        item_embedding = self.item_embed(seq_item)\n",
    "        # item position embedding\n",
    "        position_idx = torch.range(0, self.L - 1).unsqueeze(0).expand(seq_item.size(0), -1).long().to(device)\n",
    "        position_embedding = self.item_position_embed(position_idx)\n",
    "        item_embedding_cat = item_embedding.float() + position_embedding.float()\n",
    "        \n",
    "        # self-attention network\n",
    "        Q = F.relu(self.linear1(item_embedding_cat))\n",
    "        K = F.relu(self.linear1(item_embedding_cat))\n",
    "        d = torch.FloatTensor([100]).to(device)\n",
    "        affinity = torch.matmul(Q, torch.transpose(K, 1, 2))/torch.sqrt(d)\n",
    "        \n",
    "        # mask the diagonal value\n",
    "        mask = torch.eye(item_embedding_cat.size(1), item_embedding_cat.size(1)).byte().to(device)\n",
    "        affinity = affinity.masked_fill(mask, 0)\n",
    "        S = F.softmax(affinity)\n",
    "        attention = torch.mean(torch.matmul(S, item_embedding_cat), dim=1)\n",
    "        \n",
    "        # user embedding\n",
    "        user_id = user_id.to(device)\n",
    "        user_embedding = self.user_embed(user_id).squeeze()\n",
    "    \n",
    "        # target embedding short and long note: those two embedding is different \n",
    "\n",
    "        if target is None:\n",
    "            target = torch.range(0,self.num_item-1).long().unsqueeze(0).to(device)\n",
    "            target_embedding = self.item_embed(target).squeeze()\n",
    "        else:\n",
    "            target = target.to(device)\n",
    "            target_embedding = self.item_embed(target).squeeze()\n",
    "            \n",
    "        # pred\n",
    "        if for_pred == False:\n",
    "            user_embedding = user_embedding.unsqueeze(1).expand(-1,target.size(1),-1)\n",
    "            attention = attention.unsqueeze(1).expand(-1,target.size(1),-1)\n",
    "            y_pred = self.w* torch.sqrt(torch.sum((user_embedding - target_embedding)**2, dim=2)) + (1-self.w)*torch.sqrt(torch.sum((attention-target_embedding)**2, dim=2))\n",
    "            return y_pred\n",
    "        else:\n",
    "            user_embedding = user_embedding.unsqueeze(0).expand(target.size(1),-1)\n",
    "            attention = attention.expand(target.size(1),-1)\n",
    "            y_pred = self.w* torch.sqrt(torch.sum((user_embedding - target_embedding)**2, dim=1)) + (1-self.w)*torch.sqrt(torch.sum((attention-target_embedding)**2, dim=1))\n",
    "            return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "num_user = len(df_input['user_id'].unique())\n",
    "num_item = len(df_input['poi_id'].unique())\n",
    "L = 5\n",
    "embedding_dim = 100\n",
    "w = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, test_data, epochs):\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001,weight_decay=0.0001)\n",
    "    for epoch in range(epochs):\n",
    "        losses = []\n",
    "        start = time.time()\n",
    "        for train_x, train_y in dataloader:\n",
    "            user = train_x[:,0]\n",
    "            item_seq = train_x[:,1:]\n",
    "            #print(item_seq.type)\n",
    "            target_pos = train_y[:,:3]\n",
    "            target_neg = train_y[:,3:]\n",
    "            y_pred_pos = model(user, item_seq, target_pos,for_pred=False)\n",
    "            y_pred_neg = model(user, item_seq, target_neg, for_pred=False)\n",
    "            optimizer.zero_grad()\n",
    "            loss = torch.zeros(y_pred_pos.size(0),1).to(device)\n",
    "            #loss = torch.zeros(y_pred_pos.size(0),1)\n",
    "            for i in range(y_pred_pos.size(1)):\n",
    "                l = y_pred_pos[:,i].view(-1,1)\n",
    "                y_pos_slice = l.expand(-1,y_pred_pos.size(1))\n",
    "                loss += torch.sum(y_pos_slice - y_pred_neg + 0.5,dim=1).unsqueeze(1)\n",
    "            loss = torch.mean(loss)\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(\"Epoch %d loss is %.3f and consume time is %.2f\" %(epoch+1, np.mean(losses), (time.time() - start)))\n",
    "        hr, mrr = test(model, test_data, 50)\n",
    "        print(\"hr is %.3f and mrr is %.3f\" %(hr, mrr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hr(y_target, y_pred, topk):\n",
    "    y_pred = y_pred[:topk].cpu().numpy()\n",
    "    for item in y_pred:\n",
    "        if item in y_target:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def mrr(y_target, y_pred, topk):\n",
    "    y_pred = y_pred[:topk].cpu().numpy()\n",
    "    for idx in range(len(y_pred)):\n",
    "        if y_pred[idx] in y_target:\n",
    "            return 1/(idx+1)\n",
    "    return 0\n",
    "\n",
    "def test(model, test_data, topk):\n",
    "    model.eval()\n",
    "    HR = []\n",
    "    MRR = []\n",
    "    for idx in range(test_data.size(0)):\n",
    "        uid = test_data[idx,0].unsqueeze(0)\n",
    "        item_seq = test_data[idx, 1:6].unsqueeze(0)\n",
    "        y_target = test_data[idx,6:9].numpy()\n",
    "        y_pred = model(uid, item_seq,for_pred=True)\n",
    "        y_pred = torch.argsort(y_pred)\n",
    "        hits = hr(y_target, y_pred, topk)\n",
    "        mrrs = mrr(y_target, y_pred, topk)\n",
    "        HR.append(hits)\n",
    "        MRR.append(mrrs)\n",
    "    return np.mean(HR), np.mean(MRR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=100, out_features=100, bias=True)\n",
      "Epoch 1 loss is 3.058 and consume time is 4.23\n",
      "hr is 0.004 and mrr is 0.000\n",
      "Epoch 2 loss is 0.747 and consume time is 3.65\n",
      "hr is 0.003 and mrr is 0.000\n",
      "Epoch 3 loss is -1.146 and consume time is 3.70\n",
      "hr is 0.004 and mrr is 0.000\n",
      "Epoch 4 loss is -2.802 and consume time is 3.93\n",
      "hr is 0.005 and mrr is 0.000\n",
      "Epoch 5 loss is -4.277 and consume time is 3.69\n",
      "hr is 0.005 and mrr is 0.000\n",
      "Epoch 6 loss is -5.593 and consume time is 3.76\n",
      "hr is 0.007 and mrr is 0.000\n",
      "Epoch 7 loss is -6.771 and consume time is 3.70\n",
      "hr is 0.006 and mrr is 0.000\n",
      "Epoch 8 loss is -7.814 and consume time is 3.71\n",
      "hr is 0.006 and mrr is 0.000\n",
      "Epoch 9 loss is -8.745 and consume time is 3.68\n",
      "hr is 0.007 and mrr is 0.000\n",
      "Epoch 10 loss is -9.573 and consume time is 3.67\n",
      "hr is 0.006 and mrr is 0.000\n",
      "Epoch 11 loss is -10.309 and consume time is 3.70\n",
      "hr is 0.005 and mrr is 0.000\n",
      "Epoch 12 loss is -10.968 and consume time is 3.66\n",
      "hr is 0.005 and mrr is 0.000\n",
      "Epoch 13 loss is -11.553 and consume time is 3.81\n",
      "hr is 0.005 and mrr is 0.000\n",
      "Epoch 14 loss is -12.068 and consume time is 3.71\n",
      "hr is 0.005 and mrr is 0.000\n",
      "Epoch 15 loss is -12.529 and consume time is 3.68\n",
      "hr is 0.005 and mrr is 0.000\n",
      "Epoch 16 loss is -12.940 and consume time is 3.74\n",
      "hr is 0.005 and mrr is 0.000\n",
      "Epoch 17 loss is -13.308 and consume time is 3.63\n",
      "hr is 0.005 and mrr is 0.000\n",
      "Epoch 18 loss is -13.638 and consume time is 3.65\n",
      "hr is 0.004 and mrr is 0.000\n",
      "Epoch 19 loss is -13.946 and consume time is 3.73\n",
      "hr is 0.004 and mrr is 0.000\n",
      "Epoch 20 loss is -14.218 and consume time is 3.81\n",
      "hr is 0.004 and mrr is 0.000\n"
     ]
    }
   ],
   "source": [
    "selfatt = model(num_user, num_item, L, w, embedding_dim, device).to(device)\n",
    "train(selfatt,dataloader,test_data,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
