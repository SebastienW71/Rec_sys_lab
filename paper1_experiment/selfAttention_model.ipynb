{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check gpu device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>poi_id</th>\n",
       "      <th>poi_category_id</th>\n",
       "      <th>poi_category_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>time_offset</th>\n",
       "      <th>UTC_time</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4abc1f51f964a520798620e3</td>\n",
       "      <td>4bf58dd8d48988d1ce941735</td>\n",
       "      <td>Seafood Restaurant</td>\n",
       "      <td>40.781558</td>\n",
       "      <td>-73.975792</td>\n",
       "      <td>-240</td>\n",
       "      <td>Wed Apr 04 23:31:31 +0000 2012</td>\n",
       "      <td>2012-04-04 23:31:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4d4ac10da0ef54814b6ffff6</td>\n",
       "      <td>4bf58dd8d48988d157941735</td>\n",
       "      <td>American Restaurant</td>\n",
       "      <td>40.784018</td>\n",
       "      <td>-73.974524</td>\n",
       "      <td>-240</td>\n",
       "      <td>Sat Apr 07 17:42:24 +0000 2012</td>\n",
       "      <td>2012-04-07 17:42:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4db44994cda1c57c82583709</td>\n",
       "      <td>4bf58dd8d48988d1f1931735</td>\n",
       "      <td>General Entertainment</td>\n",
       "      <td>40.739398</td>\n",
       "      <td>-73.993210</td>\n",
       "      <td>-240</td>\n",
       "      <td>Sun Apr 08 18:20:29 +0000 2012</td>\n",
       "      <td>2012-04-08 18:20:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4a541923f964a52008b31fe3</td>\n",
       "      <td>4bf58dd8d48988d14e941735</td>\n",
       "      <td>American Restaurant</td>\n",
       "      <td>40.785677</td>\n",
       "      <td>-73.976498</td>\n",
       "      <td>-240</td>\n",
       "      <td>Sun Apr 08 20:02:10 +0000 2012</td>\n",
       "      <td>2012-04-08 20:02:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>40f1d480f964a5205b0a1fe3</td>\n",
       "      <td>4bf58dd8d48988d143941735</td>\n",
       "      <td>Breakfast Spot</td>\n",
       "      <td>40.719929</td>\n",
       "      <td>-74.008532</td>\n",
       "      <td>-240</td>\n",
       "      <td>Mon Apr 09 16:20:52 +0000 2012</td>\n",
       "      <td>2012-04-09 16:20:52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                    poi_id           poi_category_id  \\\n",
       "0        1  4abc1f51f964a520798620e3  4bf58dd8d48988d1ce941735   \n",
       "1        1  4d4ac10da0ef54814b6ffff6  4bf58dd8d48988d157941735   \n",
       "2        1  4db44994cda1c57c82583709  4bf58dd8d48988d1f1931735   \n",
       "3        1  4a541923f964a52008b31fe3  4bf58dd8d48988d14e941735   \n",
       "4        1  40f1d480f964a5205b0a1fe3  4bf58dd8d48988d143941735   \n",
       "\n",
       "       poi_category_name   latitude  longitude  time_offset  \\\n",
       "0     Seafood Restaurant  40.781558 -73.975792         -240   \n",
       "1    American Restaurant  40.784018 -73.974524         -240   \n",
       "2  General Entertainment  40.739398 -73.993210         -240   \n",
       "3    American Restaurant  40.785677 -73.976498         -240   \n",
       "4         Breakfast Spot  40.719929 -74.008532         -240   \n",
       "\n",
       "                         UTC_time             datetime  \n",
       "0  Wed Apr 04 23:31:31 +0000 2012  2012-04-04 23:31:31  \n",
       "1  Sat Apr 07 17:42:24 +0000 2012  2012-04-07 17:42:24  \n",
       "2  Sun Apr 08 18:20:29 +0000 2012  2012-04-08 18:20:29  \n",
       "3  Sun Apr 08 20:02:10 +0000 2012  2012-04-08 20:02:10  \n",
       "4  Mon Apr 09 16:20:52 +0000 2012  2012-04-09 16:20:52  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "dir = 'E:\\\\Sebnewrepo/Rec_sys_lab/paper1_experiment/'\n",
    "checkin_file = 'ny_ordered.csv'\n",
    "df = pd.read_csv(dir + checkin_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>poi_category_id</th>\n",
       "      <th>poi_category_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>time_offset</th>\n",
       "      <th>UTC_time</th>\n",
       "      <th>datetime</th>\n",
       "      <th>poi_encode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4bf58dd8d48988d1ce941735</td>\n",
       "      <td>Seafood Restaurant</td>\n",
       "      <td>40.781558</td>\n",
       "      <td>-73.975792</td>\n",
       "      <td>-240</td>\n",
       "      <td>Wed Apr 04 23:31:31 +0000 2012</td>\n",
       "      <td>2012-04-04 23:31:31</td>\n",
       "      <td>2752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4bf58dd8d48988d157941735</td>\n",
       "      <td>American Restaurant</td>\n",
       "      <td>40.784018</td>\n",
       "      <td>-73.974524</td>\n",
       "      <td>-240</td>\n",
       "      <td>Sat Apr 07 17:42:24 +0000 2012</td>\n",
       "      <td>2012-04-07 17:42:24</td>\n",
       "      <td>7093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4bf58dd8d48988d1f1931735</td>\n",
       "      <td>General Entertainment</td>\n",
       "      <td>40.739398</td>\n",
       "      <td>-73.993210</td>\n",
       "      <td>-240</td>\n",
       "      <td>Sun Apr 08 18:20:29 +0000 2012</td>\n",
       "      <td>2012-04-08 18:20:29</td>\n",
       "      <td>7455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4bf58dd8d48988d14e941735</td>\n",
       "      <td>American Restaurant</td>\n",
       "      <td>40.785677</td>\n",
       "      <td>-73.976498</td>\n",
       "      <td>-240</td>\n",
       "      <td>Sun Apr 08 20:02:10 +0000 2012</td>\n",
       "      <td>2012-04-08 20:02:10</td>\n",
       "      <td>1958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4bf58dd8d48988d143941735</td>\n",
       "      <td>Breakfast Spot</td>\n",
       "      <td>40.719929</td>\n",
       "      <td>-74.008532</td>\n",
       "      <td>-240</td>\n",
       "      <td>Mon Apr 09 16:20:52 +0000 2012</td>\n",
       "      <td>2012-04-09 16:20:52</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id           poi_category_id      poi_category_name   latitude  \\\n",
       "0        1  4bf58dd8d48988d1ce941735     Seafood Restaurant  40.781558   \n",
       "1        1  4bf58dd8d48988d157941735    American Restaurant  40.784018   \n",
       "2        1  4bf58dd8d48988d1f1931735  General Entertainment  40.739398   \n",
       "3        1  4bf58dd8d48988d14e941735    American Restaurant  40.785677   \n",
       "4        1  4bf58dd8d48988d143941735         Breakfast Spot  40.719929   \n",
       "\n",
       "   longitude  time_offset                        UTC_time  \\\n",
       "0 -73.975792         -240  Wed Apr 04 23:31:31 +0000 2012   \n",
       "1 -73.974524         -240  Sat Apr 07 17:42:24 +0000 2012   \n",
       "2 -73.993210         -240  Sun Apr 08 18:20:29 +0000 2012   \n",
       "3 -73.976498         -240  Sun Apr 08 20:02:10 +0000 2012   \n",
       "4 -74.008532         -240  Mon Apr 09 16:20:52 +0000 2012   \n",
       "\n",
       "              datetime  poi_encode  \n",
       "0  2012-04-04 23:31:31        2752  \n",
       "1  2012-04-07 17:42:24        7093  \n",
       "2  2012-04-08 18:20:29        7455  \n",
       "3  2012-04-08 20:02:10        1958  \n",
       "4  2012-04-09 16:20:52         499  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POIs encode, and generate encode mapping\n",
    "poi_cat = pd.Categorical(df['poi_id'])\n",
    "poi_encode = poi_cat.codes\n",
    "#generate poi mapping table\n",
    "poi_mapping = pd.DataFrame({\n",
    "    'poi_encode': poi_encode,\n",
    "    'poi_id': df['poi_id']\n",
    "    })\n",
    "#drop duplicate\n",
    "poi_mapping_output = poi_mapping.drop_duplicates()\n",
    "df['poi_encode'] = poi_encode\n",
    "df.drop(['poi_id'], axis = 1, inplace = True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep user id and sequential POIs\n",
    "\n",
    "df_input = pd.DataFrame({\n",
    "    'user_id': df['user_id'],  # user_id offset by 1\n",
    "    'poi_id': df['poi_encode'],\n",
    "    #'implicit': np.ones(179468)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>poi_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>7455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179463</th>\n",
       "      <td>1083</td>\n",
       "      <td>1541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179464</th>\n",
       "      <td>1083</td>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179465</th>\n",
       "      <td>1083</td>\n",
       "      <td>8703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179466</th>\n",
       "      <td>1083</td>\n",
       "      <td>9987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179467</th>\n",
       "      <td>1083</td>\n",
       "      <td>1956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179468 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  poi_id\n",
       "0             1    2752\n",
       "1             1    7093\n",
       "2             1    7455\n",
       "3             1    1958\n",
       "4             1     499\n",
       "...         ...     ...\n",
       "179463     1083    1541\n",
       "179464     1083     466\n",
       "179465     1083    8703\n",
       "179466     1083    9987\n",
       "179467     1083    1956\n",
       "\n",
       "[179468 rows x 2 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input = df_input.reset_index(drop = True)\n",
    "df_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1083"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9989"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input['poi_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy \n",
    "def convert_data(data):\n",
    "    df = deepcopy(data)\n",
    "    data = df.groupby('user_id')['poi_id'].apply(list)\n",
    "    unique_data = df.groupby('user_id')['poi_id'].nunique()\n",
    "    print(data[:10])\n",
    "    print(len(data))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id\n",
      "1     [2752, 7093, 7455, 1958, 499, 270, 9066, 1344,...\n",
      "2     [8834, 1303, 1714, 7089, 4713, 1830, 4512, 192...\n",
      "3     [8246, 1361, 478, 9312, 816, 1028, 6685, 1194,...\n",
      "4     [3662, 3662, 3662, 3662, 3662, 8135, 3662, 298...\n",
      "5     [2000, 2000, 5223, 9244, 2328, 9244, 5223, 924...\n",
      "6     [8584, 9680, 8584, 6217, 2943, 6362, 8584, 376...\n",
      "7     [2854, 6659, 6659, 8077, 2768, 2096, 2411, 721...\n",
      "8     [2946, 2946, 2946, 2179, 2946, 2946, 2946, 294...\n",
      "9     [6942, 3547, 672, 1410, 6942, 2316, 6250, 860,...\n",
      "10    [7183, 532, 532, 1893, 928, 1233, 6883, 5607, ...\n",
      "Name: poi_id, dtype: object\n",
      "1083\n"
     ]
    }
   ],
   "source": [
    "seq_data = convert_data(df_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class selfAtt(nn.Module):\n",
    "    def __init__(self, num_user, num_item, model_args, device):\n",
    "        \n",
    "        super(selfAtt, self).__init__()\n",
    "        \n",
    "        self.args = model_args\n",
    "        # init args\n",
    "        self.embedding_dim = self.args.d\n",
    "        embedding_dim = self.embedding_dim\n",
    "        self.L = self.args.L  # sequence length\n",
    "        L = self.L\n",
    "        self.w = 0.15  # learnable para\n",
    "        \n",
    "        # define embedding\n",
    "        \n",
    "        self.user_embed = nn.Embedding(num_user, embedding_dim).to(device)\n",
    "        self.item_embed = nn.Embedding(num_item, embedding_dim).to(device)\n",
    "        self.item_embed_short = nn.Embedding(num_item, embedding_dim).to(device)\n",
    "        self.item_embed_long = nn.Embedding(num_item, embedding_dim).to(device)\n",
    "        self.linear1 = nn.Linear(embedding_dim, embedding_dim).to(device)\n",
    "        #print(self.linear1)\n",
    "        self.item_position_embed = nn.Embedding.from_pretrained(self.position_embed(L),freeze=True)\n",
    "        \n",
    "        # initialize\n",
    "        self.user_embed.weight.data.normal_(0, 1.0/self.user_embed.embedding_dim)\n",
    "        self.item_embed.weight.data.normal_(0, 1.0/self.item_embed.embedding_dim)\n",
    "        self.linear1.weight.data.normal_(mean=0, std=np.sqrt(2.0 / embedding_dim))\n",
    "    \n",
    "    def position_embed(self, L):\n",
    "        position_embedding = np.array([[pos/np.power(1000, 2.*i)/ self.embedding_dim for i in range(self.embedding_dim)]\n",
    "                                      for pos in range(L)])\n",
    "        position_embedding[:,0::2] = np.sin(position_embedding[:,0::2])\n",
    "        position_embedding[:,1::2] = np.cos(position_embedding[:,1::2])\n",
    "        t = torch.from_numpy(position_embedding).to(device)\n",
    "        return t\n",
    "    \n",
    "    def forward(self, seq_item, user_id, target, for_pred = False):\n",
    "        \n",
    "        '''\n",
    "        user_id\n",
    "        seq_item = L item id that user interact before\n",
    "        target: item target\n",
    "        '''\n",
    "        \n",
    "        # sequential item embedding\n",
    "        # seq_item = seq_item.to(device)\n",
    "        item_embedding = self.item_embed(seq_item).to(device)\n",
    "        # item position embedding\n",
    "        position_idx = torch.range(0, self.L - 1).unsqueeze(0).expand(seq_item.size(0), -1).long().to(device)\n",
    "        position_embedding = self.item_position_embed(position_idx)\n",
    "        item_embedding_cat = item_embedding.float() + position_embedding.float()\n",
    "        \n",
    "        # self-attention network\n",
    "        Q = F.relu(self.linear1(item_embedding_cat))\n",
    "        K = F.relu(self.linear1(item_embedding_cat))\n",
    "        #print(K.shape)\n",
    "        d = torch.FloatTensor([self.embedding_dim]).to(device)\n",
    "        affinity = torch.matmul(Q, torch.transpose(K, 1, 2))/torch.sqrt(d)\n",
    "        \n",
    "        # mask the diagonal value\n",
    "        mask = torch.eye(item_embedding_cat.size(1), item_embedding_cat.size(1)).byte().to(device)\n",
    "        affinity = affinity.masked_fill(mask, 0)\n",
    "        #S = F.softmax(affinity)\n",
    "        S = torch.sigmoid(affinity)\n",
    "        #print('s', S.shape)\n",
    "        attention = torch.mean(torch.matmul(S, item_embedding_cat), dim=1)\n",
    "        \n",
    "        # user embedding\n",
    "        user_id = user_id.to(device)\n",
    "        user_embedding = self.user_embed(user_id).squeeze()\n",
    "        #print('user_embed', user_embedding.shape)\n",
    "        # target embedding short and long note: those two embedding is different \n",
    "        \n",
    "        if target is None:\n",
    "            target = torch.range(0,self.num_item-1).long().unsqueeze(0).cuda()\n",
    "            target_embedding_short = self.item_embed_short(target).squeeze()\n",
    "            target_embedding_long = self.item_embed_long(target).squeeze()\n",
    "        else:\n",
    "            target_embedding_short = self.item_embed_short(target).squeeze()\n",
    "            target_embedding_long = self.item_embed_long(target).squeeze()\n",
    "        \n",
    "        # pred\n",
    "        if for_pred == False:\n",
    "            user_embedding = user_embedding.unsqueeze(1).expand(-1,target.size(1),-1)\n",
    "            #print('to train', user_embedding.shape)\n",
    "            #print('attention before', attention.shape)\n",
    "            attention = attention.unsqueeze(1).expand(-1,target.size(1),-1)\n",
    "            #print('attention', attention.shape)\n",
    "            y_pred = self.w* torch.sqrt(torch.sum((user_embedding - target_embedding_long)**2, dim=2)) + (1-self.w)*torch.sqrt(torch.sum((attention-target_embedding_short)**2, dim=2))\n",
    "            #print('to train', y_pred)\n",
    "            return y_pred\n",
    "        else:\n",
    "            target = target.unsqueeze(0)\n",
    "            #print('target_size', target.shape)\n",
    "            #print('user_embedding', user_embedding.shape)\n",
    "            user_embedding = user_embedding.unsqueeze(0).expand(target.size(1), -1)\n",
    "            #print('user_embedding_after', user_embedding.shape)\n",
    "            #print('attention_before', attention.shape)\n",
    "            attention = attention.expand(target.size(1), -1)\n",
    "            #print('attention', attention.shape)\n",
    "            y_pred = self.w* torch.sqrt(torch.sum((user_embedding - target_embedding_long)**2, dim=1)) + (1-self.w)*torch.sqrt(torch.sum((attention-target_embedding_short)**2, dim=1))\n",
    "            return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interactions import Interactions\n",
    "from eval_metrics import *\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "from time import time\n",
    "import datetime\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, train, test_set, topk=20):\n",
    "    model.eval()\n",
    "    num_users = train.num_users\n",
    "    num_items = train.num_items\n",
    "    batch_size = 500\n",
    "    num_batches = int(num_users / batch_size) + 1\n",
    "    user_indexes = np.arange(num_users)\n",
    "    item_indexes = np.arange(num_items)\n",
    "    pred_list = None\n",
    "    train_matrix = train.tocsr()\n",
    "    test_sequences = train.test_sequences.sequences\n",
    "\n",
    "    for batchID in range(num_batches):\n",
    "        start = batchID * batch_size\n",
    "        end = start + batch_size\n",
    "\n",
    "        if batchID == num_batches - 1:\n",
    "            if start < num_users:\n",
    "                end = num_users\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        batch_user_index = user_indexes[start:end]\n",
    "        batch_test_sequences = test_sequences[batch_user_index]\n",
    "        batch_test_sequences = np.atleast_2d(batch_test_sequences)\n",
    "        batch_test_sequences = torch.from_numpy(batch_test_sequences).type(torch.LongTensor).to(device)\n",
    "        item_ids = torch.from_numpy(item_indexes).type(torch.LongTensor).to(device)\n",
    "        #print('item_ids', item_ids)\n",
    "        batch_user_ids = torch.from_numpy(np.array(batch_user_index)).type(torch.LongTensor).to(device) \n",
    "        #print('batch_user_ids', batch_user_ids)\n",
    "        # get te prediction rating: for_pred = True\n",
    "        rating_pred = np.empty([batch_user_ids.size(0),item_ids.size(0)])\n",
    "        #print(rating_pred[.shape])\n",
    "        for idx in range(batch_user_ids.size(0)):\n",
    "            uid = torch.tensor([idx])\n",
    "            #print('uid', uid)\n",
    "            #print('uid_seq', batch_test_sequences[idx].unsqueeze(0))\n",
    "            uid_pred = model(batch_test_sequences[idx].unsqueeze(0), uid, item_ids, True)\n",
    "            rating_pred[idx] = uid_pred.cpu().detach().numpy()\n",
    "        #rating_pred = model(batch_test_sequences, batch_user_ids, item_ids, True)\n",
    "        #rating_pred = rating_pred.data.numpy().copy()\n",
    "        rating_pred[train_matrix[batch_user_index].toarray() > 0] = 0\n",
    "        #print(rating_pred[0])\n",
    "        \n",
    "        # reference: https://stackoverflow.com/a/23734295, https://stackoverflow.com/a/20104162\n",
    "        ind = np.argpartition(rating_pred, -topk)\n",
    "        ind = ind[:, -topk:]\n",
    "        arr_ind = rating_pred[np.arange(len(rating_pred))[:, None], ind]\n",
    "        arr_ind_argsort = np.argsort(arr_ind)[np.arange(len(rating_pred)), ::-1]\n",
    "        batch_pred_list = ind[np.arange(len(rating_pred))[:, None], arr_ind_argsort]\n",
    "        #print('batch_pred_list', batch_pred_list.shape)\n",
    "\n",
    "        if batchID == 0:\n",
    "            pred_list = batch_pred_list\n",
    "        else:\n",
    "            pred_list = np.append(pred_list, batch_pred_list, axis=0)\n",
    "\n",
    "    precision, recall, MAP, ndcg = [], [], [], []\n",
    "    for k in [5, 10, 15, 20]:\n",
    "        precision.append(precision_at_k(test_set, pred_list, k))\n",
    "        recall.append(recall_at_k(test_set, pred_list, k))\n",
    "        MAP.append(mapk(test_set, pred_list, k))\n",
    "        ndcg.append(ndcg_k(test_set, pred_list, k))\n",
    "\n",
    "    return precision, recall, MAP, ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negsamp_vectorized_bsearch_preverif(pos_inds, n_items, n_samp=32):\n",
    "    \"\"\" Pre-verified with binary search\n",
    "    `pos_inds` is assumed to be ordered\n",
    "    reference: https://tech.hbc.com/2018-03-23-negative-sampling-in-numpy.html\n",
    "    \"\"\"\n",
    "    raw_samp = np.random.randint(0, n_items - len(pos_inds), size=n_samp)\n",
    "    pos_inds_adj = pos_inds - np.arange(len(pos_inds))\n",
    "    neg_inds = raw_samp + np.searchsorted(pos_inds_adj, raw_samp, side='right')\n",
    "    return neg_inds\n",
    "\n",
    "\n",
    "def generate_negative_samples(train_matrix, num_neg=3, num_sets=10):\n",
    "    neg_samples = []\n",
    "    for user_id, row in enumerate(train_matrix):\n",
    "        pos_ind = row.indices\n",
    "        neg_sample = negsamp_vectorized_bsearch_preverif(pos_ind, train_matrix.shape[1], num_neg * num_sets)\n",
    "        neg_samples.append(neg_sample)\n",
    "\n",
    "    return np.asarray(neg_samples).reshape(num_sets, train_matrix.shape[0], num_neg)\n",
    "\n",
    "\n",
    "def train_model(model, train_data, test_data, config):\n",
    "    num_users = train_data.num_users\n",
    "    num_items = train_data.num_items\n",
    "\n",
    "    # convert to sequences, targets and users\n",
    "    sequences_np = train_data.sequences.sequences\n",
    "    #print(sequences_np)\n",
    "    targets_np = train_data.sequences.targets\n",
    "    users_np = train_data.sequences.user_ids\n",
    "    train_matrix = train_data.tocsr()\n",
    "\n",
    "    n_train = sequences_np.shape[0]\n",
    "    logger.info(\"Total training records:{}\".format(n_train))\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate, weight_decay=config.l2)\n",
    "\n",
    "    record_indexes = np.arange(n_train)\n",
    "    batch_size = config.batch_size\n",
    "    num_batches = int(n_train / batch_size) + 1\n",
    "    for epoch_num in range(config.n_iter):\n",
    "\n",
    "        t1 = time()\n",
    "\n",
    "        # set model to training mode\n",
    "        model.train()\n",
    "\n",
    "        np.random.shuffle(record_indexes)\n",
    "\n",
    "        t_neg_start = time()\n",
    "        negatives_np_multi = generate_negative_samples(train_matrix, config.neg_samples, config.sets_of_neg_samples)\n",
    "        logger.info(\"Negative sampling time: {}s\".format(time() - t_neg_start))\n",
    "\n",
    "        epoch_loss = 0.0\n",
    "        for batchID in range(num_batches):\n",
    "            start = batchID * batch_size\n",
    "            end = start + batch_size\n",
    "\n",
    "            if batchID == num_batches - 1:\n",
    "                if start < n_train:\n",
    "                    end = n_train\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            batch_record_index = record_indexes[start:end]\n",
    "\n",
    "            batch_users = users_np[batch_record_index]\n",
    "            batch_sequences = sequences_np[batch_record_index]\n",
    "            batch_targets = targets_np[batch_record_index]\n",
    "            negatives_np = negatives_np_multi[batchID % config.sets_of_neg_samples]\n",
    "            batch_neg = negatives_np[batch_users]\n",
    "\n",
    "            batch_users = torch.from_numpy(batch_users).type(torch.LongTensor).to(device)\n",
    "            batch_sequences = torch.from_numpy(batch_sequences).type(torch.LongTensor).to(device)\n",
    "            batch_targets = torch.from_numpy(batch_targets).type(torch.LongTensor).to(device)\n",
    "            batch_negatives = torch.from_numpy(batch_neg).type(torch.LongTensor).to(device)\n",
    "\n",
    "            items_to_predict = torch.cat((batch_targets, batch_negatives), 1)\n",
    "            prediction_score = model(batch_sequences, batch_users, items_to_predict, False)\n",
    "            #print(prediction_score.shape)\n",
    "            (targets_prediction, negatives_prediction) = torch.split(\n",
    "                prediction_score, [batch_targets.size(1), batch_negatives.size(1)], dim=1)\n",
    "\n",
    "            # compute the hinge loss\n",
    "            #loss = torch.mean(F.relu(targets_prediction - negatives_prediction + 0.5), dim=1).unsqueeze(1)\n",
    "            loss = -torch.log(torch.sigmoid(targets_prediction - negatives_prediction) + 1e-8)\n",
    "            loss = torch.mean(torch.sum(loss))\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # clean the grad, \n",
    "            #optimizer.zero_grad()\n",
    "        epoch_loss /= num_batches\n",
    "\n",
    "        t2 = time()\n",
    "\n",
    "        output_str = \"Epoch %d [%.1f s]  loss=%.4f\" % (epoch_num + 1, t2 - t1, epoch_loss)\n",
    "        logger.info(output_str)\n",
    "\n",
    "        \n",
    "        if (epoch_num + 1) % 20 == 0:\n",
    "            precision, recall, MAP, ndcg = evaluation(model, train_data, test_data, topk=20)\n",
    "            logger.info(', '.join(str(e) for e in precision))\n",
    "            logger.info(', '.join(str(e) for e in recall))\n",
    "            logger.info(', '.join(str(e) for e in MAP))\n",
    "            logger.info(', '.join(str(e) for e in ndcg))\n",
    "            logger.info(\"Evaluation time:{}\".format(time() - t2))\n",
    "    logger.info(\"\\n\")\n",
    "    logger.info(\"\\n\")\n",
    "    torch.save(model.state_dict(), 'car.pkl')\n",
    "    print('model arg save complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train test data        \n",
    "def split_data_sequentially(user_records, test_radio=0.2):\n",
    "    train_set = []\n",
    "    test_set = []\n",
    "\n",
    "    for item_list in user_records:\n",
    "        len_list = len(item_list)\n",
    "        num_test_samples = int(math.ceil(len_list * test_radio))\n",
    "        train_sample = []\n",
    "        test_sample = []\n",
    "        for i in range(len_list - num_test_samples, len_list):\n",
    "            test_sample.append(item_list[i])\n",
    "            \n",
    "        for place in item_list:\n",
    "            if place not in set(test_sample):\n",
    "                train_sample.append(place)\n",
    "                \n",
    "        train_set.append(train_sample)\n",
    "        test_set.append(test_sample)\n",
    "\n",
    "    return train_set, test_set\n",
    "    \n",
    "\n",
    "def generate_dataset(seq_data):\n",
    "    user_records = seq_data.tolist()\n",
    "    # split dataset\n",
    "    train_val_set, test_set = split_data_sequentially(user_records, test_radio=0.2)\n",
    "    train_set, val_set = split_data_sequentially(train_val_set, test_radio=0.1)\n",
    "\n",
    "    return train_set, val_set, train_val_set, test_set, 1083, 9989"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set, train_val_set, test_set, num_users, num_items = generate_dataset(seq_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# data arguments\n",
    "parser.add_argument('--L', type=int, default=5)\n",
    "parser.add_argument('--T', type=int, default=3)\n",
    "# train arguments\n",
    "parser.add_argument('--n_iter', type=int, default=200)\n",
    "parser.add_argument('--seed', type=int, default=1234)\n",
    "parser.add_argument('--batch_size', type=int, default=4096)\n",
    "parser.add_argument('--learning_rate', type=float, default=1e-3)\n",
    "parser.add_argument('--l2', type=float, default=1e-3)\n",
    "parser.add_argument('--neg_samples', type=int, default=3)\n",
    "parser.add_argument('--sets_of_neg_samples', type=int, default=50)\n",
    "\n",
    "# model dependent arguments\n",
    "parser.add_argument('--d', type=int, default=100)\n",
    "config = parser.parse_args(\n",
    "    args = [\n",
    "        '--L', '5',\n",
    "        '--T', '3',\n",
    "        '--n_iter', '200',\n",
    "        '--seed', '1200',\n",
    "        '--batch_size', '500',\n",
    "        '--learning_rate', '0.001',\n",
    "        '--l2', '0.001',\n",
    "        '--neg_samples', '3',\n",
    "        '--sets_of_neg_samples', '30'\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:2021-06-16 02:26:06\n",
      "INFO:__main__:Namespace(L=5, T=3, batch_size=500, d=100, l2=0.001, learning_rate=0.001, n_iter=200, neg_samples=3, seed=1200, sets_of_neg_samples=30)\n",
      "INFO:__main__:Total training records:54872\n",
      "INFO:__main__:Negative sampling time: 0.06582283973693848s\n",
      "INFO:__main__:Epoch 1 [0.7 s]  loss=1130.5610\n",
      "INFO:__main__:Negative sampling time: 0.05585217475891113s\n",
      "INFO:__main__:Epoch 2 [0.6 s]  loss=938.5752\n",
      "INFO:__main__:Negative sampling time: 0.056847333908081055s\n",
      "INFO:__main__:Epoch 3 [0.7 s]  loss=807.6032\n",
      "INFO:__main__:Negative sampling time: 0.05485248565673828s\n",
      "INFO:__main__:Epoch 4 [0.7 s]  loss=730.3921\n",
      "INFO:__main__:Negative sampling time: 0.05585050582885742s\n",
      "INFO:__main__:Epoch 5 [0.7 s]  loss=666.3008\n",
      "INFO:__main__:Negative sampling time: 0.054852962493896484s\n",
      "INFO:__main__:Epoch 6 [0.7 s]  loss=622.9861\n",
      "INFO:__main__:Negative sampling time: 0.05336332321166992s\n",
      "INFO:__main__:Epoch 7 [0.7 s]  loss=596.8564\n",
      "INFO:__main__:Negative sampling time: 0.05485343933105469s\n",
      "INFO:__main__:Epoch 8 [0.7 s]  loss=565.5240\n",
      "INFO:__main__:Negative sampling time: 0.05385541915893555s\n",
      "INFO:__main__:Epoch 9 [0.7 s]  loss=544.3384\n",
      "INFO:__main__:Negative sampling time: 0.05684804916381836s\n",
      "INFO:__main__:Epoch 10 [0.7 s]  loss=523.2656\n",
      "INFO:__main__:Negative sampling time: 0.05585074424743652s\n",
      "INFO:__main__:Epoch 11 [0.7 s]  loss=509.2752\n",
      "INFO:__main__:Negative sampling time: 0.05285978317260742s\n",
      "INFO:__main__:Epoch 12 [0.7 s]  loss=491.5612\n",
      "INFO:__main__:Negative sampling time: 0.05485343933105469s\n",
      "INFO:__main__:Epoch 13 [0.7 s]  loss=483.6409\n",
      "INFO:__main__:Negative sampling time: 0.052857160568237305s\n",
      "INFO:__main__:Epoch 14 [0.7 s]  loss=473.9485\n",
      "INFO:__main__:Negative sampling time: 0.055850982666015625s\n",
      "INFO:__main__:Epoch 15 [0.7 s]  loss=456.8560\n",
      "INFO:__main__:Negative sampling time: 0.05585217475891113s\n",
      "INFO:__main__:Epoch 16 [0.7 s]  loss=445.3951\n",
      "INFO:__main__:Negative sampling time: 0.05485224723815918s\n",
      "INFO:__main__:Epoch 17 [0.7 s]  loss=432.3058\n",
      "INFO:__main__:Negative sampling time: 0.056847333908081055s\n",
      "INFO:__main__:Epoch 18 [0.7 s]  loss=425.8814\n",
      "INFO:__main__:Negative sampling time: 0.055849552154541016s\n",
      "INFO:__main__:Epoch 19 [0.7 s]  loss=416.4590\n",
      "INFO:__main__:Negative sampling time: 0.05585074424743652s\n",
      "INFO:__main__:Epoch 20 [0.7 s]  loss=410.9406\n",
      "INFO:__main__:0.07590027700831065, 0.057248384118190554, 0.04659895352416159, 0.03975069252077562\n",
      "INFO:__main__:0.02472702658267158, 0.037550531987269035, 0.04568466609788432, 0.05198465844561874\n",
      "INFO:__main__:0.0428962757771622, 0.02585242345630157, 0.018649876873725966, 0.015244040280209896\n",
      "INFO:__main__:0.0801826973179571, 0.0659310990587128, 0.05699248025133326, 0.052265864263606555\n",
      "INFO:__main__:Evaluation time:1.8515236377716064\n",
      "INFO:__main__:Negative sampling time: 0.05485272407531738s\n",
      "INFO:__main__:Epoch 21 [0.7 s]  loss=401.9382\n",
      "INFO:__main__:Negative sampling time: 0.054852962493896484s\n",
      "INFO:__main__:Epoch 22 [0.7 s]  loss=392.7576\n",
      "INFO:__main__:Negative sampling time: 0.05485272407531738s\n",
      "INFO:__main__:Epoch 23 [0.7 s]  loss=387.4207\n",
      "INFO:__main__:Negative sampling time: 0.054852962493896484s\n",
      "INFO:__main__:Epoch 24 [0.7 s]  loss=382.8525\n",
      "INFO:__main__:Negative sampling time: 0.05523252487182617s\n",
      "INFO:__main__:Epoch 25 [0.7 s]  loss=376.4948\n",
      "INFO:__main__:Negative sampling time: 0.05585002899169922s\n",
      "INFO:__main__:Epoch 26 [0.7 s]  loss=369.4454\n",
      "INFO:__main__:Negative sampling time: 0.05285835266113281s\n",
      "INFO:__main__:Epoch 27 [0.7 s]  loss=360.4803\n",
      "INFO:__main__:Negative sampling time: 0.05485200881958008s\n",
      "INFO:__main__:Epoch 28 [0.7 s]  loss=354.4181\n",
      "INFO:__main__:Negative sampling time: 0.0548548698425293s\n",
      "INFO:__main__:Epoch 29 [0.7 s]  loss=351.5600\n",
      "INFO:__main__:Negative sampling time: 0.05585050582885742s\n",
      "INFO:__main__:Epoch 30 [0.7 s]  loss=345.0074\n",
      "INFO:__main__:Negative sampling time: 0.05584979057312012s\n",
      "INFO:__main__:Epoch 31 [0.7 s]  loss=343.0834\n",
      "INFO:__main__:Negative sampling time: 0.054852962493896484s\n",
      "INFO:__main__:Epoch 32 [0.6 s]  loss=337.9853\n",
      "INFO:__main__:Negative sampling time: 0.054853200912475586s\n",
      "INFO:__main__:Epoch 33 [0.6 s]  loss=330.9705\n",
      "INFO:__main__:Negative sampling time: 0.054852962493896484s\n",
      "INFO:__main__:Epoch 34 [0.7 s]  loss=326.1126\n",
      "INFO:__main__:Negative sampling time: 0.05336451530456543s\n",
      "INFO:__main__:Epoch 35 [0.6 s]  loss=319.5614\n",
      "INFO:__main__:Negative sampling time: 0.05485343933105469s\n",
      "INFO:__main__:Epoch 36 [0.6 s]  loss=315.9090\n",
      "INFO:__main__:Negative sampling time: 0.0553584098815918s\n",
      "INFO:__main__:Epoch 37 [0.7 s]  loss=312.0594\n",
      "INFO:__main__:Negative sampling time: 0.054854393005371094s\n",
      "INFO:__main__:Epoch 38 [0.6 s]  loss=306.2320\n",
      "INFO:__main__:Negative sampling time: 0.054853200912475586s\n",
      "INFO:__main__:Epoch 39 [0.6 s]  loss=305.3880\n",
      "INFO:__main__:Negative sampling time: 0.0553584098815918s\n",
      "INFO:__main__:Epoch 40 [0.6 s]  loss=299.6917\n",
      "INFO:__main__:0.0786703601108038, 0.05521698984302896, 0.04567559248999719, 0.03905817174515236\n",
      "INFO:__main__:0.025867245566881785, 0.03591009034089141, 0.04447472084677752, 0.05117702788840186\n",
      "INFO:__main__:0.04647891658971992, 0.026916890178663035, 0.019433429159160492, 0.015903652739901165\n",
      "INFO:__main__:0.08596149396195765, 0.06709519277146393, 0.05819570158491718, 0.053392883464700835\n",
      "INFO:__main__:Evaluation time:1.7984795570373535\n",
      "INFO:__main__:Negative sampling time: 0.05388689041137695s\n",
      "INFO:__main__:Epoch 41 [0.6 s]  loss=296.6935\n",
      "INFO:__main__:Negative sampling time: 0.054853200912475586s\n",
      "INFO:__main__:Epoch 42 [0.6 s]  loss=289.5878\n",
      "INFO:__main__:Negative sampling time: 0.05485343933105469s\n",
      "INFO:__main__:Epoch 43 [0.6 s]  loss=287.4757\n",
      "INFO:__main__:Negative sampling time: 0.05585074424743652s\n",
      "INFO:__main__:Epoch 44 [0.6 s]  loss=286.0622\n",
      "INFO:__main__:Negative sampling time: 0.05585002899169922s\n",
      "INFO:__main__:Epoch 45 [0.7 s]  loss=280.4768\n",
      "INFO:__main__:Negative sampling time: 0.056847572326660156s\n",
      "INFO:__main__:Epoch 46 [0.7 s]  loss=280.3407\n",
      "INFO:__main__:Negative sampling time: 0.052858829498291016s\n",
      "INFO:__main__:Epoch 47 [0.7 s]  loss=275.4540\n",
      "INFO:__main__:Negative sampling time: 0.05485248565673828s\n",
      "INFO:__main__:Epoch 48 [0.7 s]  loss=272.2320\n",
      "INFO:__main__:Negative sampling time: 0.05684804916381836s\n",
      "INFO:__main__:Epoch 49 [0.7 s]  loss=267.3514\n",
      "INFO:__main__:Negative sampling time: 0.05385565757751465s\n",
      "INFO:__main__:Epoch 50 [0.7 s]  loss=266.1951\n",
      "INFO:__main__:Negative sampling time: 0.05385541915893555s\n",
      "INFO:__main__:Epoch 51 [0.7 s]  loss=261.4587\n",
      "INFO:__main__:Negative sampling time: 0.05735158920288086s\n",
      "INFO:__main__:Epoch 52 [0.7 s]  loss=257.4893\n",
      "INFO:__main__:Negative sampling time: 0.05684804916381836s\n",
      "INFO:__main__:Epoch 53 [0.7 s]  loss=256.2973\n",
      "INFO:__main__:Negative sampling time: 0.05585050582885742s\n",
      "INFO:__main__:Epoch 54 [0.7 s]  loss=252.6545\n",
      "INFO:__main__:Negative sampling time: 0.05488300323486328s\n",
      "INFO:__main__:Epoch 55 [0.7 s]  loss=249.0988\n",
      "INFO:__main__:Negative sampling time: 0.055852413177490234s\n",
      "INFO:__main__:Epoch 56 [0.7 s]  loss=246.3542\n",
      "INFO:__main__:Negative sampling time: 0.05684947967529297s\n",
      "INFO:__main__:Epoch 57 [0.7 s]  loss=244.1194\n",
      "INFO:__main__:Negative sampling time: 0.05485367774963379s\n",
      "INFO:__main__:Epoch 58 [0.7 s]  loss=241.1255\n",
      "INFO:__main__:Negative sampling time: 0.053855180740356445s\n",
      "INFO:__main__:Epoch 59 [0.7 s]  loss=240.3078\n",
      "INFO:__main__:Negative sampling time: 0.05684781074523926s\n",
      "INFO:__main__:Epoch 60 [0.7 s]  loss=235.0879\n",
      "INFO:__main__:0.07590027700831067, 0.05743305632502342, 0.04647583871960637, 0.03998153277931667\n",
      "INFO:__main__:0.024862988211685474, 0.037383529152996975, 0.045653966008394026, 0.052370137703209516\n",
      "INFO:__main__:0.0422099107417667, 0.02570190095120843, 0.01840175036744395, 0.015109349308222164\n",
      "INFO:__main__:0.07966442012170742, 0.06554400890625806, 0.05651922654760484, 0.052160387610634164\n",
      "INFO:__main__:Evaluation time:1.860741376876831\n",
      "INFO:__main__:Negative sampling time: 0.055850982666015625s\n",
      "INFO:__main__:Epoch 61 [0.7 s]  loss=232.8374\n",
      "INFO:__main__:Negative sampling time: 0.054853200912475586s\n",
      "INFO:__main__:Epoch 62 [0.7 s]  loss=232.2549\n",
      "INFO:__main__:Negative sampling time: 0.05385565757751465s\n",
      "INFO:__main__:Epoch 63 [0.7 s]  loss=226.6862\n",
      "INFO:__main__:Negative sampling time: 0.056847333908081055s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Epoch 64 [0.7 s]  loss=224.4425\n",
      "INFO:__main__:Negative sampling time: 0.05635523796081543s\n",
      "INFO:__main__:Epoch 65 [0.7 s]  loss=223.4713\n",
      "INFO:__main__:Negative sampling time: 0.05485415458679199s\n",
      "INFO:__main__:Epoch 66 [0.7 s]  loss=221.1789\n",
      "INFO:__main__:Negative sampling time: 0.056847572326660156s\n",
      "INFO:__main__:Epoch 67 [0.7 s]  loss=218.3036\n",
      "INFO:__main__:Negative sampling time: 0.0548548698425293s\n",
      "INFO:__main__:Epoch 68 [0.7 s]  loss=215.6664\n",
      "INFO:__main__:Negative sampling time: 0.05385589599609375s\n",
      "INFO:__main__:Epoch 69 [0.7 s]  loss=214.0117\n",
      "INFO:__main__:Negative sampling time: 0.05585002899169922s\n",
      "INFO:__main__:Epoch 70 [0.7 s]  loss=213.3996\n",
      "INFO:__main__:Negative sampling time: 0.05584979057312012s\n",
      "INFO:__main__:Epoch 71 [0.7 s]  loss=208.9685\n",
      "INFO:__main__:Negative sampling time: 0.054852962493896484s\n",
      "INFO:__main__:Epoch 72 [0.7 s]  loss=206.1902\n",
      "INFO:__main__:Negative sampling time: 0.054852962493896484s\n",
      "INFO:__main__:Epoch 73 [0.7 s]  loss=205.9927\n",
      "INFO:__main__:Negative sampling time: 0.053856611251831055s\n",
      "INFO:__main__:Epoch 74 [0.7 s]  loss=204.5678\n",
      "INFO:__main__:Negative sampling time: 0.05385541915893555s\n",
      "INFO:__main__:Epoch 75 [0.7 s]  loss=201.7555\n",
      "INFO:__main__:Negative sampling time: 0.05585122108459473s\n",
      "INFO:__main__:Epoch 76 [0.7 s]  loss=200.6770\n",
      "INFO:__main__:Negative sampling time: 0.054852962493896484s\n",
      "INFO:__main__:Epoch 77 [0.7 s]  loss=198.5351\n",
      "INFO:__main__:Negative sampling time: 0.05585050582885742s\n",
      "INFO:__main__:Epoch 78 [0.7 s]  loss=195.4108\n",
      "INFO:__main__:Negative sampling time: 0.054852962493896484s\n",
      "INFO:__main__:Epoch 79 [0.7 s]  loss=194.1504\n",
      "INFO:__main__:Negative sampling time: 0.054853200912475586s\n",
      "INFO:__main__:Epoch 80 [0.7 s]  loss=192.3944\n",
      "INFO:__main__:0.07737765466297364, 0.05706371191135768, 0.04610649430594061, 0.039981532779316674\n",
      "INFO:__main__:0.025466836990010885, 0.03703661569029597, 0.045204418842375485, 0.052674065453342335\n",
      "INFO:__main__:0.04520775623268698, 0.026733317211156547, 0.01917086378667964, 0.015717842931427917\n",
      "INFO:__main__:0.08360977349065285, 0.06728722186281527, 0.05779226253037679, 0.053449747956978454\n",
      "INFO:__main__:Evaluation time:1.861013412475586\n",
      "INFO:__main__:Negative sampling time: 0.056847572326660156s\n",
      "INFO:__main__:Epoch 81 [0.7 s]  loss=191.4122\n",
      "INFO:__main__:Negative sampling time: 0.05535769462585449s\n",
      "INFO:__main__:Epoch 82 [0.7 s]  loss=189.5573\n",
      "INFO:__main__:Negative sampling time: 0.05485248565673828s\n",
      "INFO:__main__:Epoch 83 [0.7 s]  loss=189.6820\n",
      "INFO:__main__:Negative sampling time: 0.05285835266113281s\n",
      "INFO:__main__:Epoch 84 [0.7 s]  loss=187.4570\n",
      "INFO:__main__:Negative sampling time: 0.054852962493896484s\n",
      "INFO:__main__:Epoch 85 [0.7 s]  loss=185.0089\n",
      "INFO:__main__:Negative sampling time: 0.05485343933105469s\n",
      "INFO:__main__:Epoch 86 [0.7 s]  loss=185.3470\n",
      "INFO:__main__:Negative sampling time: 0.05585050582885742s\n",
      "INFO:__main__:Epoch 87 [0.7 s]  loss=183.5540\n",
      "INFO:__main__:Negative sampling time: 0.055853843688964844s\n",
      "INFO:__main__:Epoch 88 [0.7 s]  loss=182.2179\n",
      "INFO:__main__:Negative sampling time: 0.054853200912475586s\n",
      "INFO:__main__:Epoch 89 [0.7 s]  loss=179.5012\n",
      "INFO:__main__:Negative sampling time: 0.05588078498840332s\n",
      "INFO:__main__:Epoch 90 [0.7 s]  loss=178.7853\n",
      "INFO:__main__:Negative sampling time: 0.05535745620727539s\n",
      "INFO:__main__:Epoch 91 [0.7 s]  loss=178.2994\n",
      "INFO:__main__:Negative sampling time: 0.05485367774963379s\n",
      "INFO:__main__:Epoch 92 [0.6 s]  loss=176.5670\n",
      "INFO:__main__:Negative sampling time: 0.05485272407531738s\n",
      "INFO:__main__:Epoch 93 [0.6 s]  loss=174.6114\n",
      "INFO:__main__:Negative sampling time: 0.054852962493896484s\n",
      "INFO:__main__:Epoch 94 [0.6 s]  loss=175.4582\n",
      "INFO:__main__:Negative sampling time: 0.05485200881958008s\n",
      "INFO:__main__:Epoch 95 [0.6 s]  loss=174.2028\n",
      "INFO:__main__:Negative sampling time: 0.05535721778869629s\n",
      "INFO:__main__:Epoch 96 [0.6 s]  loss=173.0230\n",
      "INFO:__main__:Negative sampling time: 0.054852962493896484s\n",
      "INFO:__main__:Epoch 97 [0.6 s]  loss=171.8031\n",
      "INFO:__main__:Negative sampling time: 0.05485367774963379s\n",
      "INFO:__main__:Epoch 98 [0.6 s]  loss=171.6278\n",
      "INFO:__main__:Negative sampling time: 0.05485248565673828s\n",
      "INFO:__main__:Epoch 99 [0.6 s]  loss=170.4532\n",
      "INFO:__main__:Negative sampling time: 0.05585217475891113s\n",
      "INFO:__main__:Epoch 100 [0.7 s]  loss=168.8615\n",
      "INFO:__main__:0.0799630655586339, 0.058079409048938484, 0.04881502000615608, 0.04127423822714676\n",
      "INFO:__main__:0.0262864175818226, 0.037870209020762824, 0.047806783795797815, 0.053904162453003196\n",
      "INFO:__main__:0.04717143736534318, 0.027757954828591946, 0.020210146812837747, 0.016490693560981005\n",
      "INFO:__main__:0.08696305574240713, 0.06922727002626312, 0.06070592457121632, 0.05545162965099824\n",
      "INFO:__main__:Evaluation time:1.834151029586792\n",
      "INFO:__main__:Negative sampling time: 0.05585169792175293s\n",
      "INFO:__main__:Epoch 101 [0.7 s]  loss=168.1418\n",
      "INFO:__main__:Negative sampling time: 0.05535721778869629s\n",
      "INFO:__main__:Epoch 102 [0.6 s]  loss=168.0415\n",
      "INFO:__main__:Negative sampling time: 0.05485343933105469s\n",
      "INFO:__main__:Epoch 103 [0.7 s]  loss=165.7806\n",
      "INFO:__main__:Negative sampling time: 0.05585050582885742s\n",
      "INFO:__main__:Epoch 104 [0.6 s]  loss=165.4614\n",
      "INFO:__main__:Negative sampling time: 0.05585145950317383s\n",
      "INFO:__main__:Epoch 105 [0.6 s]  loss=165.6478\n",
      "INFO:__main__:Negative sampling time: 0.05485367774963379s\n",
      "INFO:__main__:Epoch 106 [0.7 s]  loss=164.5391\n",
      "INFO:__main__:Negative sampling time: 0.05485415458679199s\n",
      "INFO:__main__:Epoch 107 [0.7 s]  loss=164.3346\n",
      "INFO:__main__:Negative sampling time: 0.05518078804016113s\n",
      "INFO:__main__:Epoch 108 [0.7 s]  loss=163.3980\n",
      "INFO:__main__:Negative sampling time: 0.05585050582885742s\n",
      "INFO:__main__:Epoch 109 [0.7 s]  loss=161.2218\n",
      "INFO:__main__:Negative sampling time: 0.054854393005371094s\n",
      "INFO:__main__:Epoch 110 [0.7 s]  loss=160.7805\n",
      "INFO:__main__:Negative sampling time: 0.05685019493103027s\n",
      "INFO:__main__:Epoch 111 [0.7 s]  loss=159.7981\n",
      "INFO:__main__:Negative sampling time: 0.05385589599609375s\n",
      "INFO:__main__:Epoch 112 [0.7 s]  loss=160.3561\n",
      "INFO:__main__:Negative sampling time: 0.05585217475891113s\n",
      "INFO:__main__:Epoch 113 [0.7 s]  loss=160.0375\n",
      "INFO:__main__:Negative sampling time: 0.05531001091003418s\n",
      "INFO:__main__:Epoch 114 [0.7 s]  loss=159.0655\n",
      "INFO:__main__:Negative sampling time: 0.05585050582885742s\n",
      "INFO:__main__:Epoch 115 [0.7 s]  loss=158.5630\n",
      "INFO:__main__:Negative sampling time: 0.05585002899169922s\n",
      "INFO:__main__:Epoch 116 [0.7 s]  loss=157.2742\n",
      "INFO:__main__:Negative sampling time: 0.055853843688964844s\n",
      "INFO:__main__:Epoch 117 [0.7 s]  loss=156.9038\n",
      "INFO:__main__:Negative sampling time: 0.05687594413757324s\n",
      "INFO:__main__:Epoch 118 [0.7 s]  loss=156.0456\n",
      "INFO:__main__:Negative sampling time: 0.05585074424743652s\n",
      "INFO:__main__:Epoch 119 [0.7 s]  loss=156.4114\n",
      "INFO:__main__:Negative sampling time: 0.054852962493896484s\n",
      "INFO:__main__:Epoch 120 [0.7 s]  loss=156.1991\n",
      "INFO:__main__:0.07811634349030518, 0.05983379501385077, 0.04893813481071135, 0.042289935364727534\n",
      "INFO:__main__:0.025548358894405338, 0.03919776063242227, 0.04785384056424109, 0.05541292137722756\n",
      "INFO:__main__:0.04569098184056633, 0.027464164797959812, 0.019879607731474236, 0.016396746441412733\n",
      "INFO:__main__:0.08465635359298594, 0.06964350881729815, 0.0603325810903397, 0.055789734493535394\n",
      "INFO:__main__:Evaluation time:1.8660998344421387\n",
      "INFO:__main__:Negative sampling time: 0.05484485626220703s\n",
      "INFO:__main__:Epoch 121 [0.7 s]  loss=154.5476\n",
      "INFO:__main__:Negative sampling time: 0.05585050582885742s\n",
      "INFO:__main__:Epoch 122 [0.7 s]  loss=155.2285\n",
      "INFO:__main__:Negative sampling time: 0.05485272407531738s\n",
      "INFO:__main__:Epoch 123 [0.7 s]  loss=154.3596\n",
      "INFO:__main__:Negative sampling time: 0.055350542068481445s\n",
      "INFO:__main__:Epoch 124 [0.7 s]  loss=153.9855\n",
      "INFO:__main__:Negative sampling time: 0.056847572326660156s\n",
      "INFO:__main__:Epoch 125 [0.7 s]  loss=154.0641\n",
      "INFO:__main__:Negative sampling time: 0.05285811424255371s\n",
      "INFO:__main__:Epoch 126 [0.7 s]  loss=153.1244\n",
      "INFO:__main__:Negative sampling time: 0.054853200912475586s\n",
      "INFO:__main__:Epoch 127 [0.7 s]  loss=153.1204\n",
      "INFO:__main__:Negative sampling time: 0.05582618713378906s\n",
      "INFO:__main__:Epoch 128 [0.7 s]  loss=151.3403\n",
      "INFO:__main__:Negative sampling time: 0.056874990463256836s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Epoch 129 [0.7 s]  loss=152.7981\n",
      "INFO:__main__:Negative sampling time: 0.05585074424743652s\n",
      "INFO:__main__:Epoch 130 [0.6 s]  loss=151.4964\n",
      "INFO:__main__:Negative sampling time: 0.0548243522644043s\n",
      "INFO:__main__:Epoch 131 [0.7 s]  loss=151.3437\n",
      "INFO:__main__:Negative sampling time: 0.05385565757751465s\n",
      "INFO:__main__:Epoch 132 [0.6 s]  loss=149.6551\n",
      "INFO:__main__:Negative sampling time: 0.05585050582885742s\n",
      "INFO:__main__:Epoch 133 [0.6 s]  loss=149.3708\n",
      "INFO:__main__:Negative sampling time: 0.05382657051086426s\n",
      "INFO:__main__:Epoch 134 [0.6 s]  loss=148.6939\n",
      "INFO:__main__:Negative sampling time: 0.05482840538024902s\n",
      "INFO:__main__:Epoch 135 [0.6 s]  loss=149.6704\n",
      "INFO:__main__:Negative sampling time: 0.05485272407531738s\n",
      "INFO:__main__:Epoch 136 [0.6 s]  loss=149.4658\n",
      "INFO:__main__:Negative sampling time: 0.05285930633544922s\n",
      "INFO:__main__:Epoch 137 [0.7 s]  loss=149.3010\n",
      "INFO:__main__:Negative sampling time: 0.055850982666015625s\n",
      "INFO:__main__:Epoch 138 [0.7 s]  loss=148.3317\n",
      "INFO:__main__:Negative sampling time: 0.05585074424743652s\n",
      "INFO:__main__:Epoch 139 [0.6 s]  loss=147.7646\n",
      "INFO:__main__:Negative sampling time: 0.054853200912475586s\n",
      "INFO:__main__:Epoch 140 [0.6 s]  loss=147.1680\n",
      "INFO:__main__:0.0764542936288093, 0.05992613111726721, 0.04899969221298898, 0.043351800554016544\n",
      "INFO:__main__:0.02536561618135052, 0.0391586766201784, 0.04757025223632862, 0.05672560944288059\n",
      "INFO:__main__:0.04464450600184673, 0.027095813770944582, 0.01967136481637985, 0.0164011631154235\n",
      "INFO:__main__:0.08342904666823373, 0.06952571823707643, 0.06024020036918505, 0.056449468422333164\n",
      "INFO:__main__:Evaluation time:1.8151445388793945\n",
      "INFO:__main__:Negative sampling time: 0.055861711502075195s\n",
      "INFO:__main__:Epoch 141 [0.6 s]  loss=147.5566\n",
      "INFO:__main__:Negative sampling time: 0.05485272407531738s\n",
      "INFO:__main__:Epoch 142 [0.6 s]  loss=147.5629\n",
      "INFO:__main__:Negative sampling time: 0.05585217475891113s\n",
      "INFO:__main__:Epoch 143 [0.6 s]  loss=148.0412\n",
      "INFO:__main__:Negative sampling time: 0.05485272407531738s\n",
      "INFO:__main__:Epoch 144 [0.6 s]  loss=147.2634\n",
      "INFO:__main__:Negative sampling time: 0.054363250732421875s\n",
      "INFO:__main__:Epoch 145 [0.6 s]  loss=146.8808\n",
      "INFO:__main__:Negative sampling time: 0.05436444282531738s\n",
      "INFO:__main__:Epoch 146 [0.6 s]  loss=146.1515\n",
      "INFO:__main__:Negative sampling time: 0.055849313735961914s\n",
      "INFO:__main__:Epoch 147 [0.6 s]  loss=146.7179\n",
      "INFO:__main__:Negative sampling time: 0.054853200912475586s\n",
      "INFO:__main__:Epoch 148 [0.6 s]  loss=146.1912\n",
      "INFO:__main__:Negative sampling time: 0.05585026741027832s\n",
      "INFO:__main__:Epoch 149 [0.6 s]  loss=144.8314\n",
      "INFO:__main__:Negative sampling time: 0.054853200912475586s\n",
      "INFO:__main__:Epoch 150 [0.6 s]  loss=145.3015\n",
      "INFO:__main__:Negative sampling time: 0.054853200912475586s\n",
      "INFO:__main__:Epoch 151 [0.6 s]  loss=145.1288\n",
      "INFO:__main__:Negative sampling time: 0.054854393005371094s\n",
      "INFO:__main__:Epoch 152 [0.6 s]  loss=145.8612\n",
      "INFO:__main__:Negative sampling time: 0.05382847785949707s\n",
      "INFO:__main__:Epoch 153 [0.6 s]  loss=144.0434\n",
      "INFO:__main__:Negative sampling time: 0.05385446548461914s\n",
      "INFO:__main__:Epoch 154 [0.6 s]  loss=146.0424\n",
      "INFO:__main__:Negative sampling time: 0.055821895599365234s\n",
      "INFO:__main__:Epoch 155 [0.6 s]  loss=142.9223\n",
      "INFO:__main__:Negative sampling time: 0.05439257621765137s\n",
      "INFO:__main__:Epoch 156 [0.6 s]  loss=143.4292\n",
      "INFO:__main__:Negative sampling time: 0.05585026741027832s\n",
      "INFO:__main__:Epoch 157 [0.6 s]  loss=143.7256\n",
      "INFO:__main__:Negative sampling time: 0.05584979057312012s\n",
      "INFO:__main__:Epoch 158 [0.6 s]  loss=143.9114\n",
      "INFO:__main__:Negative sampling time: 0.05485200881958008s\n",
      "INFO:__main__:Epoch 159 [0.6 s]  loss=144.4499\n",
      "INFO:__main__:Negative sampling time: 0.05482316017150879s\n",
      "INFO:__main__:Epoch 160 [0.6 s]  loss=144.1023\n",
      "INFO:__main__:0.07811634349030522, 0.061588180978763014, 0.05115420129270587, 0.04464450600184661\n",
      "INFO:__main__:0.02579292561766138, 0.041172409033275105, 0.05070710476155228, 0.0585290136446836\n",
      "INFO:__main__:0.04555247768544167, 0.02774366878860569, 0.020267368725245875, 0.016797349067078842\n",
      "INFO:__main__:0.08534735536768225, 0.0714332380225395, 0.06246976942000898, 0.05818074418553415\n",
      "INFO:__main__:Evaluation time:1.809607982635498\n",
      "INFO:__main__:Negative sampling time: 0.05585622787475586s\n",
      "INFO:__main__:Epoch 161 [0.7 s]  loss=142.4831\n",
      "INFO:__main__:Negative sampling time: 0.05485272407531738s\n",
      "INFO:__main__:Epoch 162 [0.6 s]  loss=141.2253\n",
      "INFO:__main__:Negative sampling time: 0.05482792854309082s\n",
      "INFO:__main__:Epoch 163 [0.7 s]  loss=142.7509\n",
      "INFO:__main__:Negative sampling time: 0.05585455894470215s\n",
      "INFO:__main__:Epoch 164 [0.6 s]  loss=142.0511\n",
      "INFO:__main__:Negative sampling time: 0.05581927299499512s\n",
      "INFO:__main__:Epoch 165 [0.6 s]  loss=141.9036\n",
      "INFO:__main__:Negative sampling time: 0.05435967445373535s\n",
      "INFO:__main__:Epoch 166 [0.6 s]  loss=141.0875\n",
      "INFO:__main__:Negative sampling time: 0.05585002899169922s\n",
      "INFO:__main__:Epoch 167 [0.6 s]  loss=142.3499\n",
      "INFO:__main__:Negative sampling time: 0.05488085746765137s\n",
      "INFO:__main__:Epoch 168 [0.6 s]  loss=141.4573\n",
      "INFO:__main__:Negative sampling time: 0.055879831314086914s\n",
      "INFO:__main__:Epoch 169 [0.6 s]  loss=142.8405\n",
      "INFO:__main__:Negative sampling time: 0.055357933044433594s\n",
      "INFO:__main__:Epoch 170 [0.6 s]  loss=140.1299\n",
      "INFO:__main__:Negative sampling time: 0.05385565757751465s\n",
      "INFO:__main__:Epoch 171 [0.6 s]  loss=140.4323\n",
      "INFO:__main__:Negative sampling time: 0.05385613441467285s\n",
      "INFO:__main__:Epoch 172 [0.6 s]  loss=141.4780\n",
      "INFO:__main__:Negative sampling time: 0.05385637283325195s\n",
      "INFO:__main__:Epoch 173 [0.6 s]  loss=140.5756\n",
      "INFO:__main__:Negative sampling time: 0.056848764419555664s\n",
      "INFO:__main__:Epoch 174 [0.6 s]  loss=139.8311\n",
      "INFO:__main__:Negative sampling time: 0.055357933044433594s\n",
      "INFO:__main__:Epoch 175 [0.6 s]  loss=140.9794\n",
      "INFO:__main__:Negative sampling time: 0.05385541915893555s\n",
      "INFO:__main__:Epoch 176 [0.6 s]  loss=139.6221\n",
      "INFO:__main__:Negative sampling time: 0.05585050582885742s\n",
      "INFO:__main__:Epoch 177 [0.6 s]  loss=140.9887\n",
      "INFO:__main__:Negative sampling time: 0.05485224723815918s\n",
      "INFO:__main__:Epoch 178 [0.6 s]  loss=139.9733\n",
      "INFO:__main__:Negative sampling time: 0.05485200881958008s\n",
      "INFO:__main__:Epoch 179 [0.7 s]  loss=139.3569\n",
      "INFO:__main__:Negative sampling time: 0.05535888671875s\n",
      "INFO:__main__:Epoch 180 [0.6 s]  loss=140.1821\n",
      "INFO:__main__:0.08144044321329691, 0.06398891966759027, 0.052262234533703135, 0.04575253924284382\n",
      "INFO:__main__:0.02687342446062766, 0.04249911514717342, 0.05189810741717282, 0.06005887029917884\n",
      "INFO:__main__:0.04826100338565712, 0.029272486772486773, 0.021158790937184285, 0.017573351502642606\n",
      "INFO:__main__:0.08953805632885484, 0.07456376768969472, 0.06453380863319295, 0.06008485212179797\n",
      "INFO:__main__:Evaluation time:1.8882031440734863\n",
      "INFO:__main__:Negative sampling time: 0.0579679012298584s\n",
      "INFO:__main__:Epoch 181 [0.7 s]  loss=138.3475\n",
      "INFO:__main__:Negative sampling time: 0.05387306213378906s\n",
      "INFO:__main__:Epoch 182 [0.7 s]  loss=139.3276\n",
      "INFO:__main__:Negative sampling time: 0.05485343933105469s\n",
      "INFO:__main__:Epoch 183 [0.6 s]  loss=140.6996\n",
      "INFO:__main__:Negative sampling time: 0.053855180740356445s\n",
      "INFO:__main__:Epoch 184 [0.6 s]  loss=140.1017\n",
      "INFO:__main__:Negative sampling time: 0.053885698318481445s\n",
      "INFO:__main__:Epoch 185 [0.7 s]  loss=138.1276\n",
      "INFO:__main__:Negative sampling time: 0.05585026741027832s\n",
      "INFO:__main__:Epoch 186 [0.6 s]  loss=138.1350\n",
      "INFO:__main__:Negative sampling time: 0.056009769439697266s\n",
      "INFO:__main__:Epoch 187 [0.6 s]  loss=137.8046\n",
      "INFO:__main__:Negative sampling time: 0.05585002899169922s\n",
      "INFO:__main__:Epoch 188 [0.6 s]  loss=137.2767\n",
      "INFO:__main__:Negative sampling time: 0.05385541915893555s\n",
      "INFO:__main__:Epoch 189 [0.6 s]  loss=137.7925\n",
      "INFO:__main__:Negative sampling time: 0.056848764419555664s\n",
      "INFO:__main__:Epoch 190 [0.7 s]  loss=137.2011\n",
      "INFO:__main__:Negative sampling time: 0.054853200912475586s\n",
      "INFO:__main__:Epoch 191 [0.6 s]  loss=139.2665\n",
      "INFO:__main__:Negative sampling time: 0.05642056465148926s\n",
      "INFO:__main__:Epoch 192 [0.6 s]  loss=137.2561\n",
      "INFO:__main__:Negative sampling time: 0.05485177040100098s\n",
      "INFO:__main__:Epoch 193 [0.6 s]  loss=138.5483\n",
      "INFO:__main__:Negative sampling time: 0.05385541915893555s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Epoch 194 [0.6 s]  loss=136.6721\n",
      "INFO:__main__:Negative sampling time: 0.05487847328186035s\n",
      "INFO:__main__:Epoch 195 [0.6 s]  loss=137.1843\n",
      "INFO:__main__:Negative sampling time: 0.05485343933105469s\n",
      "INFO:__main__:Epoch 196 [0.6 s]  loss=138.5037\n",
      "INFO:__main__:Negative sampling time: 0.05385637283325195s\n",
      "INFO:__main__:Epoch 197 [0.6 s]  loss=137.5601\n",
      "INFO:__main__:Negative sampling time: 0.05385565757751465s\n",
      "INFO:__main__:Epoch 198 [0.6 s]  loss=138.0825\n",
      "INFO:__main__:Negative sampling time: 0.05585050582885742s\n",
      "INFO:__main__:Epoch 199 [0.6 s]  loss=137.9581\n",
      "INFO:__main__:Negative sampling time: 0.05581927299499512s\n",
      "INFO:__main__:Epoch 200 [0.6 s]  loss=136.8811\n",
      "INFO:__main__:0.08199445983379551, 0.06288088642659309, 0.053370267774700365, 0.04538319482917809\n",
      "INFO:__main__:0.026997148711968587, 0.041430855850649255, 0.052476483476491496, 0.05977717867965697\n",
      "INFO:__main__:0.04813173284087412, 0.02891280345112293, 0.021275930865364976, 0.017480086785049736\n",
      "INFO:__main__:0.08920989653923503, 0.07342118931223933, 0.06491375942160915, 0.059520185007598654\n",
      "INFO:__main__:Evaluation time:1.816293478012085\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model arg save complete\n"
     ]
    }
   ],
   "source": [
    "train = Interactions(train_val_set, num_users, num_items)\n",
    "train.to_sequence(config.L, config.T)\n",
    "\n",
    "logger.info(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "logger.info(config)\n",
    "model = selfAtt(num_users, num_items, config, device).to(device)\n",
    "train_model(model, train, test_set, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
