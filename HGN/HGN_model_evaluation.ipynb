{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HGN Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dir = 'E:\\Sebnewrepo\\Rec_sys_lab\\HGN/'\n",
    "user_record_file = 'Books_item_sequences.pkl'\n",
    "user_mapping_file = 'Books_user_mapping.pkl'\n",
    "item_mapping_file = 'Books_item_mapping.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import HGN Model and Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gating_network import HGN\n",
    "from interactions import Interactions\n",
    "from eval_metrics import *\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "from time import time\n",
    "import datetime\n",
    "import torch\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the device if available\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(hgn, train, test_set, topk=20):\n",
    "    num_users = train.num_users\n",
    "    num_items = train.num_items\n",
    "    batch_size = 1024\n",
    "    num_batches = int(num_users / batch_size) + 1\n",
    "    user_indexes = np.arange(num_users)\n",
    "    item_indexes = np.arange(num_items)\n",
    "    pred_list = None\n",
    "    train_matrix = train.tocsr()\n",
    "    test_sequences = train.test_sequences.sequences\n",
    "\n",
    "    for batchID in range(num_batches):\n",
    "        start = batchID * batch_size\n",
    "        end = start + batch_size\n",
    "\n",
    "        if batchID == num_batches - 1:\n",
    "            if start < num_users:\n",
    "                end = num_users\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        batch_user_index = user_indexes[start:end]\n",
    "\n",
    "        batch_test_sequences = test_sequences[batch_user_index]\n",
    "        batch_test_sequences = np.atleast_2d(batch_test_sequences)\n",
    "\n",
    "        batch_test_sequences = torch.from_numpy(batch_test_sequences).type(torch.LongTensor).to(device)\n",
    "        item_ids = torch.from_numpy(item_indexes).type(torch.LongTensor).to(device)\n",
    "        batch_user_ids = torch.from_numpy(np.array(batch_user_index)).type(torch.LongTensor).to(device)\n",
    "\n",
    "        rating_pred = hgn(batch_test_sequences, batch_user_ids, item_ids, True)\n",
    "        rating_pred = rating_pred.cpu().data.numpy().copy()\n",
    "        rating_pred[train_matrix[batch_user_index].toarray() > 0] = 0\n",
    "\n",
    "        # reference: https://stackoverflow.com/a/23734295, https://stackoverflow.com/a/20104162\n",
    "        ind = np.argpartition(rating_pred, -topk)\n",
    "        ind = ind[:, -topk:]\n",
    "        arr_ind = rating_pred[np.arange(len(rating_pred))[:, None], ind]\n",
    "        arr_ind_argsort = np.argsort(arr_ind)[np.arange(len(rating_pred)), ::-1]\n",
    "        batch_pred_list = ind[np.arange(len(rating_pred))[:, None], arr_ind_argsort]\n",
    "\n",
    "        if batchID == 0:\n",
    "            pred_list = batch_pred_list\n",
    "        else:\n",
    "            pred_list = np.append(pred_list, batch_pred_list, axis=0)\n",
    "\n",
    "    precision, recall, MAP, ndcg = [], [], [], []\n",
    "    for k in [5, 10, 15, 20]:\n",
    "        precision.append(precision_at_k(test_set, pred_list, k))\n",
    "        recall.append(recall_at_k(test_set, pred_list, k))\n",
    "        MAP.append(mapk(test_set, pred_list, k))\n",
    "        ndcg.append(ndcg_k(test_set, pred_list, k))\n",
    "\n",
    "    return precision, recall, MAP, ndcg\n",
    "\n",
    "\n",
    "def negsamp_vectorized_bsearch_preverif(pos_inds, n_items, n_samp=32):\n",
    "    \"\"\" Pre-verified with binary search\n",
    "    `pos_inds` is assumed to be ordered\n",
    "    reference: https://tech.hbc.com/2018-03-23-negative-sampling-in-numpy.html\n",
    "    \"\"\"\n",
    "    raw_samp = np.random.randint(0, n_items - len(pos_inds), size=n_samp)\n",
    "    pos_inds_adj = pos_inds - np.arange(len(pos_inds))\n",
    "    neg_inds = raw_samp + np.searchsorted(pos_inds_adj, raw_samp, side='right')\n",
    "    return neg_inds\n",
    "\n",
    "\n",
    "def generate_negative_samples(train_matrix, num_neg=3, num_sets=10):\n",
    "    neg_samples = []\n",
    "    for user_id, row in enumerate(train_matrix):\n",
    "        pos_ind = row.indices\n",
    "        neg_sample = negsamp_vectorized_bsearch_preverif(pos_ind, train_matrix.shape[1], num_neg * num_sets)\n",
    "        neg_samples.append(neg_sample)\n",
    "\n",
    "    return np.asarray(neg_samples).reshape(num_sets, train_matrix.shape[0], num_neg)\n",
    "\n",
    "\n",
    "def train_model(train_data, test_data, config):\n",
    "    num_users = train_data.num_users\n",
    "    num_items = train_data.num_items\n",
    "\n",
    "    # convert to sequences, targets and users\n",
    "    sequences_np = train_data.sequences.sequences\n",
    "    targets_np = train_data.sequences.targets\n",
    "    users_np = train_data.sequences.user_ids\n",
    "    train_matrix = train_data.tocsr()\n",
    "\n",
    "    n_train = sequences_np.shape[0]\n",
    "    logger.info(\"Total training records:{}\".format(n_train))\n",
    "\n",
    "    hgn = HGN(num_users, num_items, config, device).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(hgn.parameters(), lr=config.learning_rate, weight_decay=config.l2)\n",
    "\n",
    "    record_indexes = np.arange(n_train)\n",
    "    batch_size = config.batch_size\n",
    "    num_batches = int(n_train / batch_size) + 1\n",
    "    for epoch_num in range(config.n_iter):\n",
    "\n",
    "        t1 = time()\n",
    "\n",
    "        # set model to training mode\n",
    "        hgn.train()\n",
    "\n",
    "        np.random.shuffle(record_indexes)\n",
    "\n",
    "        t_neg_start = time()\n",
    "        negatives_np_multi = generate_negative_samples(train_matrix, config.neg_samples, config.sets_of_neg_samples)\n",
    "        logger.info(\"Negative sampling time: {}s\".format(time() - t_neg_start))\n",
    "\n",
    "        epoch_loss = 0.0\n",
    "        for batchID in range(num_batches):\n",
    "            start = batchID * batch_size\n",
    "            end = start + batch_size\n",
    "\n",
    "            if batchID == num_batches - 1:\n",
    "                if start < n_train:\n",
    "                    end = n_train\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            batch_record_index = record_indexes[start:end]\n",
    "\n",
    "            batch_users = users_np[batch_record_index]\n",
    "            batch_sequences = sequences_np[batch_record_index]\n",
    "            batch_targets = targets_np[batch_record_index]\n",
    "            negatives_np = negatives_np_multi[batchID % config.sets_of_neg_samples]\n",
    "            batch_neg = negatives_np[batch_users]\n",
    "\n",
    "            batch_users = torch.from_numpy(batch_users).type(torch.LongTensor).to(device)\n",
    "            batch_sequences = torch.from_numpy(batch_sequences).type(torch.LongTensor).to(device)\n",
    "            batch_targets = torch.from_numpy(batch_targets).type(torch.LongTensor).to(device)\n",
    "            batch_negatives = torch.from_numpy(batch_neg).type(torch.LongTensor).to(device)\n",
    "\n",
    "            items_to_predict = torch.cat((batch_targets, batch_negatives), 1)\n",
    "            prediction_score = hgn(batch_sequences, batch_users, items_to_predict, False)\n",
    "\n",
    "            (targets_prediction, negatives_prediction) = torch.split(\n",
    "                prediction_score, [batch_targets.size(1), batch_negatives.size(1)], dim=1)\n",
    "\n",
    "            # compute the BPR loss\n",
    "            loss = -torch.log(torch.sigmoid(targets_prediction - negatives_prediction) + 1e-8)\n",
    "            loss = torch.mean(torch.sum(loss))\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # clean the grad, \n",
    "            #optimizer.zero_grad()\n",
    "        epoch_loss /= num_batches\n",
    "\n",
    "        t2 = time()\n",
    "\n",
    "        output_str = \"Epoch %d [%.1f s]  loss=%.4f\" % (epoch_num + 1, t2 - t1, epoch_loss)\n",
    "        logger.info(output_str)\n",
    "\n",
    "        if (epoch_num + 1) % 20 == 0:\n",
    "            hgn.eval()\n",
    "            precision, recall, MAP, ndcg = evaluation(hgn, train_data, test_data, topk=20)\n",
    "            logger.info(', '.join(str(e) for e in precision))\n",
    "            logger.info(', '.join(str(e) for e in recall))\n",
    "            logger.info(', '.join(str(e) for e in MAP))\n",
    "            logger.info(', '.join(str(e) for e in ndcg))\n",
    "            logger.info(\"Evaluation time:{}\".format(time() - t2))\n",
    "    logger.info(\"\\n\")\n",
    "    logger.info(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset and split train-test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(name):\n",
    "    with open(name, 'rb') as f:\n",
    "        return pickle.load(f, encoding='latin1')\n",
    "\n",
    "# split train test data        \n",
    "def split_data_sequentially(user_records, test_radio=0.2):\n",
    "    train_set = []\n",
    "    test_set = []\n",
    "\n",
    "    for item_list in user_records:\n",
    "        len_list = len(item_list)\n",
    "        num_test_samples = int(math.ceil(len_list * test_radio))\n",
    "        train_sample = []\n",
    "        test_sample = []\n",
    "        for i in range(len_list - num_test_samples, len_list):\n",
    "            test_sample.append(item_list[i])\n",
    "            \n",
    "        for place in item_list:\n",
    "            if place not in set(test_sample):\n",
    "                train_sample.append(place)\n",
    "                \n",
    "        train_set.append(train_sample)\n",
    "        test_set.append(test_sample)\n",
    "\n",
    "    return train_set, test_set\n",
    "    \n",
    "def data_index_shift(lists, increase_by):\n",
    "    '''\n",
    "    Increase the item index to contain the pad_index\n",
    "    :param lists:\n",
    "    :param increase_by: 1\n",
    "    :return:\n",
    "    '''\n",
    "    \n",
    "    for seq in lists:\n",
    "        for i, item_id in enumerate(seq):\n",
    "            seq[i] = item_id + increase_by\n",
    "\n",
    "    return lists\n",
    "\n",
    "def generate_dataset(index_shift=1):\n",
    "    user_records = load_pickle(dir + user_record_file)\n",
    "    user_mapping = load_pickle(dir + user_mapping_file)\n",
    "    item_mapping = load_pickle(dir + item_mapping_file)\n",
    "        \n",
    "    # validate the input data\n",
    "    #assert len(user_mapping) == 52406 and len(item_mapping) == 41264\n",
    "    # apply small dataset\n",
    "    #user_records = user_records[0:10000]\n",
    "    #user_mapping = user_mapping[0:10000]\n",
    "    \n",
    "    user_records = data_index_shift(user_records, increase_by=index_shift)\n",
    "\n",
    "    # split dataset\n",
    "    train_val_set, test_set = split_data_sequentially(user_records, test_radio=0.2)\n",
    "    train_set, val_set = split_data_sequentially(train_val_set, test_radio=0.1)\n",
    "\n",
    "    return train_set, val_set, train_val_set, test_set, len(user_mapping), len(item_mapping) + index_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train test dataset\n",
    "# item_id=0 for sequence padding\n",
    "train_set, val_set, train_val_set, test_set, num_users, num_items = generate_dataset(index_shift = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# data arguments\n",
    "parser.add_argument('--L', type=int, default=5)\n",
    "parser.add_argument('--T', type=int, default=3)\n",
    "# train arguments\n",
    "parser.add_argument('--n_iter', type=int, default=200)\n",
    "parser.add_argument('--seed', type=int, default=1234)\n",
    "parser.add_argument('--batch_size', type=int, default=4096)\n",
    "parser.add_argument('--learning_rate', type=float, default=1e-3)\n",
    "parser.add_argument('--l2', type=float, default=1e-3)\n",
    "parser.add_argument('--neg_samples', type=int, default=3)\n",
    "parser.add_argument('--sets_of_neg_samples', type=int, default=50)\n",
    "\n",
    "# model dependent arguments\n",
    "parser.add_argument('--d', type=int, default=50)\n",
    "config = parser.parse_args(\n",
    "    args = [\n",
    "        '--L', '5',\n",
    "        '--T', '3',\n",
    "        '--n_iter', '200',\n",
    "        '--seed', '1200',\n",
    "        '--batch_size', '4000',\n",
    "        '--learning_rate', '0.001',\n",
    "        '--l2', '0.001',\n",
    "        '--neg_samples', '3',\n",
    "        '--sets_of_neg_samples', '50'\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:2021-04-06 20:29:44\n",
      "INFO:__main__:Namespace(L=5, T=3, batch_size=4000, d=50, l2=0.001, learning_rate=0.001, n_iter=200, neg_samples=3, seed=1200, sets_of_neg_samples=50)\n",
      "INFO:__main__:Total training records:1097612\n",
      "INFO:__main__:Negative sampling time: 2.686659574508667s\n",
      "INFO:__main__:Epoch 1 [6.3 s]  loss=6415.4372\n",
      "INFO:__main__:Negative sampling time: 2.6934211254119873s\n",
      "INFO:__main__:Epoch 2 [5.1 s]  loss=2541.7489\n",
      "INFO:__main__:Negative sampling time: 2.6937978267669678s\n",
      "INFO:__main__:Epoch 3 [5.1 s]  loss=1663.1394\n",
      "INFO:__main__:Negative sampling time: 2.690415382385254s\n",
      "INFO:__main__:Epoch 4 [5.1 s]  loss=1315.9076\n",
      "INFO:__main__:Negative sampling time: 2.6655640602111816s\n",
      "INFO:__main__:Epoch 5 [5.0 s]  loss=1118.0570\n",
      "INFO:__main__:Negative sampling time: 2.6628358364105225s\n",
      "INFO:__main__:Epoch 6 [5.0 s]  loss=986.4791\n",
      "INFO:__main__:Negative sampling time: 2.6871228218078613s\n",
      "INFO:__main__:Epoch 7 [5.1 s]  loss=887.3044\n",
      "INFO:__main__:Negative sampling time: 2.6580631732940674s\n",
      "INFO:__main__:Epoch 8 [5.0 s]  loss=812.8716\n",
      "INFO:__main__:Negative sampling time: 2.6786980628967285s\n",
      "INFO:__main__:Epoch 9 [5.1 s]  loss=751.2215\n",
      "INFO:__main__:Negative sampling time: 2.6462831497192383s\n",
      "INFO:__main__:Epoch 10 [5.0 s]  loss=702.7788\n",
      "INFO:__main__:Negative sampling time: 2.6566760540008545s\n",
      "INFO:__main__:Epoch 11 [5.0 s]  loss=657.7421\n",
      "INFO:__main__:Negative sampling time: 2.6563961505889893s\n",
      "INFO:__main__:Epoch 12 [5.0 s]  loss=622.7955\n",
      "INFO:__main__:Negative sampling time: 2.6999895572662354s\n",
      "INFO:__main__:Epoch 13 [5.1 s]  loss=585.8209\n",
      "INFO:__main__:Negative sampling time: 2.6685993671417236s\n",
      "INFO:__main__:Epoch 14 [5.0 s]  loss=560.4076\n",
      "INFO:__main__:Negative sampling time: 2.68190336227417s\n",
      "INFO:__main__:Epoch 15 [5.1 s]  loss=533.7714\n",
      "INFO:__main__:Negative sampling time: 2.6956231594085693s\n",
      "INFO:__main__:Epoch 16 [5.1 s]  loss=508.7919\n",
      "INFO:__main__:Negative sampling time: 2.7022194862365723s\n",
      "INFO:__main__:Epoch 17 [5.1 s]  loss=488.5649\n",
      "INFO:__main__:Negative sampling time: 2.6580238342285156s\n",
      "INFO:__main__:Epoch 18 [5.0 s]  loss=464.6894\n",
      "INFO:__main__:Negative sampling time: 2.680058717727661s\n",
      "INFO:__main__:Epoch 19 [5.1 s]  loss=446.8872\n",
      "INFO:__main__:Negative sampling time: 2.67380952835083s\n",
      "INFO:__main__:Epoch 20 [5.0 s]  loss=432.6118\n",
      "INFO:__main__:0.028477655230320087, 0.024052589398160577, 0.021355061125319756, 0.019604625424566827\n",
      "INFO:__main__:0.021994349862714212, 0.03672518957807687, 0.04830793935292219, 0.05869606122394163\n",
      "INFO:__main__:0.018319006093449858, 0.01700053723468663, 0.017319381625136344, 0.017806331829993263\n",
      "INFO:__main__:0.03280262163248601, 0.03660287205324183, 0.04054948818744238, 0.04422556500955668\n",
      "INFO:__main__:Evaluation time:53.79132843017578\n",
      "INFO:__main__:Negative sampling time: 2.6416285037994385s\n",
      "INFO:__main__:Epoch 21 [5.0 s]  loss=419.7384\n",
      "INFO:__main__:Negative sampling time: 2.6350221633911133s\n",
      "INFO:__main__:Epoch 22 [5.0 s]  loss=399.4678\n",
      "INFO:__main__:Negative sampling time: 2.64985728263855s\n",
      "INFO:__main__:Epoch 23 [5.0 s]  loss=388.9757\n",
      "INFO:__main__:Negative sampling time: 2.6522297859191895s\n",
      "INFO:__main__:Epoch 24 [5.0 s]  loss=374.4484\n",
      "INFO:__main__:Negative sampling time: 2.6407368183135986s\n",
      "INFO:__main__:Epoch 25 [5.0 s]  loss=362.3919\n",
      "INFO:__main__:Negative sampling time: 2.6581225395202637s\n",
      "INFO:__main__:Epoch 26 [5.0 s]  loss=355.6610\n",
      "INFO:__main__:Negative sampling time: 2.632847785949707s\n",
      "INFO:__main__:Epoch 27 [5.0 s]  loss=340.4931\n",
      "INFO:__main__:Negative sampling time: 2.656557559967041s\n",
      "INFO:__main__:Epoch 28 [5.0 s]  loss=334.4733\n",
      "INFO:__main__:Negative sampling time: 2.652952194213867s\n",
      "INFO:__main__:Epoch 29 [5.0 s]  loss=326.0224\n",
      "INFO:__main__:Negative sampling time: 2.6729400157928467s\n",
      "INFO:__main__:Epoch 30 [5.0 s]  loss=317.6689\n",
      "INFO:__main__:Negative sampling time: 2.63234281539917s\n",
      "INFO:__main__:Epoch 31 [5.0 s]  loss=310.9505\n",
      "INFO:__main__:Negative sampling time: 2.6714859008789062s\n",
      "INFO:__main__:Epoch 32 [5.0 s]  loss=304.9843\n",
      "INFO:__main__:Negative sampling time: 2.654042959213257s\n",
      "INFO:__main__:Epoch 33 [5.0 s]  loss=296.0681\n",
      "INFO:__main__:Negative sampling time: 2.6552271842956543s\n",
      "INFO:__main__:Epoch 34 [5.0 s]  loss=288.3034\n",
      "INFO:__main__:Negative sampling time: 2.6504924297332764s\n",
      "INFO:__main__:Epoch 35 [5.0 s]  loss=282.7062\n",
      "INFO:__main__:Negative sampling time: 2.654299736022949s\n",
      "INFO:__main__:Epoch 36 [5.0 s]  loss=276.4801\n",
      "INFO:__main__:Negative sampling time: 2.641944408416748s\n",
      "INFO:__main__:Epoch 37 [5.0 s]  loss=272.9551\n",
      "INFO:__main__:Negative sampling time: 2.7155919075012207s\n",
      "INFO:__main__:Epoch 38 [5.1 s]  loss=266.5692\n",
      "INFO:__main__:Negative sampling time: 2.6508936882019043s\n",
      "INFO:__main__:Epoch 39 [5.0 s]  loss=260.8899\n",
      "INFO:__main__:Negative sampling time: 2.6697473526000977s\n",
      "INFO:__main__:Epoch 40 [5.0 s]  loss=256.3576\n",
      "INFO:__main__:0.03295042552379874, 0.027017898713886348, 0.023756821737971664, 0.02154428882188675\n",
      "INFO:__main__:0.025840947305346213, 0.04156959345469448, 0.053883910598846674, 0.06458930341087812\n",
      "INFO:__main__:0.021640635932272386, 0.019915251693329288, 0.020218689307114367, 0.02071592902033638\n",
      "INFO:__main__:0.03830303383122494, 0.04197614802080566, 0.04612120644904966, 0.04984753038009935\n",
      "INFO:__main__:Evaluation time:53.79407358169556\n",
      "INFO:__main__:Negative sampling time: 2.6702492237091064s\n",
      "INFO:__main__:Epoch 41 [5.0 s]  loss=255.7845\n",
      "INFO:__main__:Negative sampling time: 2.643401622772217s\n",
      "INFO:__main__:Epoch 42 [5.0 s]  loss=247.7971\n",
      "INFO:__main__:Negative sampling time: 2.6470439434051514s\n",
      "INFO:__main__:Epoch 43 [5.0 s]  loss=242.7869\n",
      "INFO:__main__:Negative sampling time: 2.655998945236206s\n",
      "INFO:__main__:Epoch 44 [5.0 s]  loss=240.3661\n",
      "INFO:__main__:Negative sampling time: 2.634725332260132s\n",
      "INFO:__main__:Epoch 45 [5.0 s]  loss=237.1460\n",
      "INFO:__main__:Negative sampling time: 2.661484718322754s\n",
      "INFO:__main__:Epoch 46 [5.0 s]  loss=234.0759\n",
      "INFO:__main__:Negative sampling time: 2.644397258758545s\n",
      "INFO:__main__:Epoch 47 [5.0 s]  loss=229.1444\n",
      "INFO:__main__:Negative sampling time: 2.659369945526123s\n",
      "INFO:__main__:Epoch 48 [5.0 s]  loss=226.5973\n",
      "INFO:__main__:Negative sampling time: 2.658406972885132s\n",
      "INFO:__main__:Epoch 49 [5.0 s]  loss=226.1897\n",
      "INFO:__main__:Negative sampling time: 2.6618964672088623s\n",
      "INFO:__main__:Epoch 50 [5.1 s]  loss=219.5549\n",
      "INFO:__main__:Negative sampling time: 2.655803918838501s\n",
      "INFO:__main__:Epoch 51 [5.0 s]  loss=216.5213\n",
      "INFO:__main__:Negative sampling time: 2.6640684604644775s\n",
      "INFO:__main__:Epoch 52 [5.1 s]  loss=215.5849\n",
      "INFO:__main__:Negative sampling time: 2.665679931640625s\n",
      "INFO:__main__:Epoch 53 [5.0 s]  loss=212.6546\n",
      "INFO:__main__:Negative sampling time: 2.6640400886535645s\n",
      "INFO:__main__:Epoch 54 [5.0 s]  loss=211.7507\n",
      "INFO:__main__:Negative sampling time: 2.6523563861846924s\n",
      "INFO:__main__:Epoch 55 [5.0 s]  loss=208.5505\n",
      "INFO:__main__:Negative sampling time: 2.649097204208374s\n",
      "INFO:__main__:Epoch 56 [5.0 s]  loss=205.6946\n",
      "INFO:__main__:Negative sampling time: 2.642886161804199s\n",
      "INFO:__main__:Epoch 57 [5.0 s]  loss=204.0388\n",
      "INFO:__main__:Negative sampling time: 2.644601821899414s\n",
      "INFO:__main__:Epoch 58 [5.0 s]  loss=201.7073\n",
      "INFO:__main__:Negative sampling time: 2.673959732055664s\n",
      "INFO:__main__:Epoch 59 [5.0 s]  loss=200.0320\n",
      "INFO:__main__:Negative sampling time: 2.6441824436187744s\n",
      "INFO:__main__:Epoch 60 [5.0 s]  loss=196.0926\n",
      "INFO:__main__:0.03427088501317038, 0.028044498721518662, 0.024476841074179807, 0.02219306949585504\n",
      "INFO:__main__:0.027124877168568717, 0.043269200068543526, 0.05575100300923693, 0.0668696241773537\n",
      "INFO:__main__:0.02263494532008634, 0.0208136934913432, 0.021135457229515358, 0.02165683018837717\n",
      "INFO:__main__:0.039909930522410736, 0.04368220998775481, 0.0478186791075603, 0.0516827483759214\n",
      "INFO:__main__:Evaluation time:53.874226331710815\n",
      "INFO:__main__:Negative sampling time: 2.665766954421997s\n",
      "INFO:__main__:Epoch 61 [5.0 s]  loss=196.1190\n",
      "INFO:__main__:Negative sampling time: 2.649777412414551s\n",
      "INFO:__main__:Epoch 62 [5.0 s]  loss=193.2463\n",
      "INFO:__main__:Negative sampling time: 2.6768734455108643s\n",
      "INFO:__main__:Epoch 63 [5.0 s]  loss=191.5264\n",
      "INFO:__main__:Negative sampling time: 2.6580636501312256s\n",
      "INFO:__main__:Epoch 64 [5.0 s]  loss=191.2393\n",
      "INFO:__main__:Negative sampling time: 2.6363956928253174s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Epoch 65 [5.0 s]  loss=187.9890\n",
      "INFO:__main__:Negative sampling time: 2.644850730895996s\n",
      "INFO:__main__:Epoch 66 [5.0 s]  loss=187.6982\n",
      "INFO:__main__:Negative sampling time: 2.6474854946136475s\n",
      "INFO:__main__:Epoch 67 [5.0 s]  loss=185.8539\n",
      "INFO:__main__:Negative sampling time: 2.635560989379883s\n",
      "INFO:__main__:Epoch 68 [5.0 s]  loss=182.8054\n",
      "INFO:__main__:Negative sampling time: 2.6380155086517334s\n",
      "INFO:__main__:Epoch 69 [5.0 s]  loss=183.4271\n",
      "INFO:__main__:Negative sampling time: 2.655147075653076s\n",
      "INFO:__main__:Epoch 70 [5.0 s]  loss=181.8195\n",
      "INFO:__main__:Negative sampling time: 2.6526641845703125s\n",
      "INFO:__main__:Epoch 71 [5.0 s]  loss=179.4419\n",
      "INFO:__main__:Negative sampling time: 2.6282079219818115s\n",
      "INFO:__main__:Epoch 72 [5.0 s]  loss=179.4560\n",
      "INFO:__main__:Negative sampling time: 2.6600608825683594s\n",
      "INFO:__main__:Epoch 73 [5.0 s]  loss=179.5548\n",
      "INFO:__main__:Negative sampling time: 2.6507601737976074s\n",
      "INFO:__main__:Epoch 74 [5.0 s]  loss=178.1740\n",
      "INFO:__main__:Negative sampling time: 2.6618800163269043s\n",
      "INFO:__main__:Epoch 75 [5.0 s]  loss=175.0765\n",
      "INFO:__main__:Negative sampling time: 2.657838821411133s\n",
      "INFO:__main__:Epoch 76 [5.0 s]  loss=172.5323\n",
      "INFO:__main__:Negative sampling time: 2.6625046730041504s\n",
      "INFO:__main__:Epoch 77 [5.0 s]  loss=174.1216\n",
      "INFO:__main__:Negative sampling time: 2.6678152084350586s\n",
      "INFO:__main__:Epoch 78 [5.0 s]  loss=172.3599\n",
      "INFO:__main__:Negative sampling time: 2.6526601314544678s\n",
      "INFO:__main__:Epoch 79 [5.0 s]  loss=173.5519\n",
      "INFO:__main__:Negative sampling time: 2.641721248626709s\n",
      "INFO:__main__:Epoch 80 [5.0 s]  loss=170.7814\n",
      "INFO:__main__:0.034049536312639954, 0.027888028088385176, 0.0244984670966454, 0.022189253138949497\n",
      "INFO:__main__:0.02688106477471547, 0.04280357159529301, 0.05558282430997787, 0.06629346922529396\n",
      "INFO:__main__:0.022384804326900654, 0.020712012039009877, 0.0210478244198792, 0.021554656775794344\n",
      "INFO:__main__:0.039587495257893915, 0.04337875999464186, 0.04767506392992263, 0.05143474563654361\n",
      "INFO:__main__:Evaluation time:54.025243282318115\n",
      "INFO:__main__:Negative sampling time: 2.651733160018921s\n",
      "INFO:__main__:Epoch 81 [5.0 s]  loss=169.9668\n",
      "INFO:__main__:Negative sampling time: 2.64711856842041s\n",
      "INFO:__main__:Epoch 82 [5.0 s]  loss=167.7409\n",
      "INFO:__main__:Negative sampling time: 2.66372013092041s\n",
      "INFO:__main__:Epoch 83 [5.0 s]  loss=168.5614\n",
      "INFO:__main__:Negative sampling time: 2.6629602909088135s\n",
      "INFO:__main__:Epoch 84 [5.0 s]  loss=166.4161\n",
      "INFO:__main__:Negative sampling time: 2.6467273235321045s\n",
      "INFO:__main__:Epoch 85 [5.0 s]  loss=166.6220\n",
      "INFO:__main__:Negative sampling time: 2.653066873550415s\n",
      "INFO:__main__:Epoch 86 [5.0 s]  loss=166.2472\n",
      "INFO:__main__:Negative sampling time: 2.659467935562134s\n",
      "INFO:__main__:Epoch 87 [5.0 s]  loss=164.9349\n",
      "INFO:__main__:Negative sampling time: 2.648897409439087s\n",
      "INFO:__main__:Epoch 88 [5.0 s]  loss=164.0340\n",
      "INFO:__main__:Negative sampling time: 2.65427565574646s\n",
      "INFO:__main__:Epoch 89 [5.0 s]  loss=161.6606\n",
      "INFO:__main__:Negative sampling time: 2.658123254776001s\n",
      "INFO:__main__:Epoch 90 [5.0 s]  loss=162.1758\n",
      "INFO:__main__:Negative sampling time: 2.659147024154663s\n",
      "INFO:__main__:Epoch 91 [5.0 s]  loss=161.4067\n",
      "INFO:__main__:Negative sampling time: 2.6477863788604736s\n",
      "INFO:__main__:Epoch 92 [5.0 s]  loss=160.2896\n",
      "INFO:__main__:Negative sampling time: 2.638502597808838s\n",
      "INFO:__main__:Epoch 93 [5.0 s]  loss=159.8212\n",
      "INFO:__main__:Negative sampling time: 2.6501054763793945s\n",
      "INFO:__main__:Epoch 94 [5.0 s]  loss=159.9333\n",
      "INFO:__main__:Negative sampling time: 2.6287245750427246s\n",
      "INFO:__main__:Epoch 95 [5.0 s]  loss=159.8587\n",
      "INFO:__main__:Negative sampling time: 2.64650559425354s\n",
      "INFO:__main__:Epoch 96 [5.0 s]  loss=157.4059\n",
      "INFO:__main__:Negative sampling time: 2.6716933250427246s\n",
      "INFO:__main__:Epoch 97 [5.1 s]  loss=157.2260\n",
      "INFO:__main__:Negative sampling time: 2.6393282413482666s\n",
      "INFO:__main__:Epoch 98 [5.0 s]  loss=156.9950\n",
      "INFO:__main__:Negative sampling time: 2.6435465812683105s\n",
      "INFO:__main__:Epoch 99 [5.0 s]  loss=157.0870\n",
      "INFO:__main__:Negative sampling time: 2.6359431743621826s\n",
      "INFO:__main__:Epoch 100 [5.0 s]  loss=158.0673\n",
      "INFO:__main__:0.033820554898298064, 0.02773919016906303, 0.024383976389474493, 0.022073808342552077\n",
      "INFO:__main__:0.026457622829540527, 0.042716253825722784, 0.055563439814760876, 0.0663740016844794\n",
      "INFO:__main__:0.022402513283042227, 0.020618910199189308, 0.020929123532575755, 0.02142712394308475\n",
      "INFO:__main__:0.039505384893234664, 0.043254895515640185, 0.04756188292407009, 0.05132728866646663\n",
      "INFO:__main__:Evaluation time:54.043068647384644\n",
      "INFO:__main__:Negative sampling time: 2.6818912029266357s\n",
      "INFO:__main__:Epoch 101 [5.1 s]  loss=155.8723\n",
      "INFO:__main__:Negative sampling time: 2.6487081050872803s\n",
      "INFO:__main__:Epoch 102 [5.0 s]  loss=154.7880\n",
      "INFO:__main__:Negative sampling time: 2.638284921646118s\n",
      "INFO:__main__:Epoch 103 [5.0 s]  loss=154.6780\n",
      "INFO:__main__:Negative sampling time: 2.63498592376709s\n",
      "INFO:__main__:Epoch 104 [5.0 s]  loss=152.9529\n",
      "INFO:__main__:Negative sampling time: 2.6560323238372803s\n",
      "INFO:__main__:Epoch 105 [5.0 s]  loss=154.2541\n",
      "INFO:__main__:Negative sampling time: 2.6269638538360596s\n",
      "INFO:__main__:Epoch 106 [5.0 s]  loss=153.1469\n",
      "INFO:__main__:Negative sampling time: 2.626715898513794s\n",
      "INFO:__main__:Epoch 107 [5.0 s]  loss=153.1684\n",
      "INFO:__main__:Negative sampling time: 2.63427996635437s\n",
      "INFO:__main__:Epoch 108 [5.0 s]  loss=152.2868\n",
      "INFO:__main__:Negative sampling time: 2.6479101181030273s\n",
      "INFO:__main__:Epoch 109 [5.0 s]  loss=149.2881\n",
      "INFO:__main__:Negative sampling time: 2.6455585956573486s\n",
      "INFO:__main__:Epoch 110 [5.0 s]  loss=152.1540\n",
      "INFO:__main__:Negative sampling time: 2.638896942138672s\n",
      "INFO:__main__:Epoch 111 [5.0 s]  loss=151.1283\n",
      "INFO:__main__:Negative sampling time: 2.666574239730835s\n",
      "INFO:__main__:Epoch 112 [5.1 s]  loss=150.8370\n",
      "INFO:__main__:Negative sampling time: 2.6584861278533936s\n",
      "INFO:__main__:Epoch 113 [5.1 s]  loss=150.6596\n",
      "INFO:__main__:Negative sampling time: 2.6616461277008057s\n",
      "INFO:__main__:Epoch 114 [5.0 s]  loss=149.1519\n",
      "INFO:__main__:Negative sampling time: 2.665348768234253s\n",
      "INFO:__main__:Epoch 115 [5.1 s]  loss=149.5620\n",
      "INFO:__main__:Negative sampling time: 2.637265682220459s\n",
      "INFO:__main__:Epoch 116 [5.0 s]  loss=147.7809\n",
      "INFO:__main__:Negative sampling time: 2.6518423557281494s\n",
      "INFO:__main__:Epoch 117 [5.0 s]  loss=147.1416\n",
      "INFO:__main__:Negative sampling time: 2.628063678741455s\n",
      "INFO:__main__:Epoch 118 [5.0 s]  loss=146.9755\n",
      "INFO:__main__:Negative sampling time: 2.6546177864074707s\n",
      "INFO:__main__:Epoch 119 [5.0 s]  loss=147.1022\n",
      "INFO:__main__:Negative sampling time: 2.637573003768921s\n",
      "INFO:__main__:Epoch 120 [5.0 s]  loss=146.9862\n",
      "INFO:__main__:0.033561042628710534, 0.027441514330418616, 0.024037960030024647, 0.021784719306945595\n",
      "INFO:__main__:0.026085857809668576, 0.04225051850449144, 0.05456790832028808, 0.06524920975683905\n",
      "INFO:__main__:0.02196396086962053, 0.020208377380933396, 0.020517162605260767, 0.021023302294003253\n",
      "INFO:__main__:0.03890120426843875, 0.04262395329033471, 0.04675712982724392, 0.050490532891253444\n",
      "INFO:__main__:Evaluation time:54.12893772125244\n",
      "INFO:__main__:Negative sampling time: 2.6487252712249756s\n",
      "INFO:__main__:Epoch 121 [5.0 s]  loss=146.5073\n",
      "INFO:__main__:Negative sampling time: 2.639179229736328s\n",
      "INFO:__main__:Epoch 122 [5.0 s]  loss=146.4453\n",
      "INFO:__main__:Negative sampling time: 2.6653337478637695s\n",
      "INFO:__main__:Epoch 123 [5.0 s]  loss=147.1353\n",
      "INFO:__main__:Negative sampling time: 2.6730716228485107s\n",
      "INFO:__main__:Epoch 124 [5.1 s]  loss=145.9755\n",
      "INFO:__main__:Negative sampling time: 2.6541619300842285s\n",
      "INFO:__main__:Epoch 125 [5.0 s]  loss=146.4074\n",
      "INFO:__main__:Negative sampling time: 2.656029224395752s\n",
      "INFO:__main__:Epoch 126 [5.0 s]  loss=145.1810\n",
      "INFO:__main__:Negative sampling time: 2.6442534923553467s\n",
      "INFO:__main__:Epoch 127 [5.0 s]  loss=144.6671\n",
      "INFO:__main__:Negative sampling time: 2.651721477508545s\n",
      "INFO:__main__:Epoch 128 [5.0 s]  loss=145.0075\n",
      "INFO:__main__:Negative sampling time: 2.6549885272979736s\n",
      "INFO:__main__:Epoch 129 [5.0 s]  loss=144.7217\n",
      "INFO:__main__:Negative sampling time: 2.656127691268921s\n",
      "INFO:__main__:Epoch 130 [5.0 s]  loss=144.4081\n",
      "INFO:__main__:Negative sampling time: 2.6533093452453613s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Epoch 131 [5.0 s]  loss=143.6516\n",
      "INFO:__main__:Negative sampling time: 2.679453134536743s\n",
      "INFO:__main__:Epoch 132 [5.1 s]  loss=145.7058\n",
      "INFO:__main__:Negative sampling time: 2.661573648452759s\n",
      "INFO:__main__:Epoch 133 [5.1 s]  loss=143.7133\n",
      "INFO:__main__:Negative sampling time: 2.649965286254883s\n",
      "INFO:__main__:Epoch 134 [5.0 s]  loss=142.5904\n",
      "INFO:__main__:Negative sampling time: 2.662989616394043s\n",
      "INFO:__main__:Epoch 135 [5.0 s]  loss=141.6642\n",
      "INFO:__main__:Negative sampling time: 2.641047477722168s\n",
      "INFO:__main__:Epoch 136 [5.0 s]  loss=142.7882\n",
      "INFO:__main__:Negative sampling time: 2.663923978805542s\n",
      "INFO:__main__:Epoch 137 [5.0 s]  loss=142.4747\n",
      "INFO:__main__:Negative sampling time: 2.652670383453369s\n",
      "INFO:__main__:Epoch 138 [5.0 s]  loss=142.9124\n",
      "INFO:__main__:Negative sampling time: 2.646897077560425s\n",
      "INFO:__main__:Epoch 139 [5.0 s]  loss=140.1096\n",
      "INFO:__main__:Negative sampling time: 2.6587743759155273s\n",
      "INFO:__main__:Epoch 140 [5.0 s]  loss=140.9118\n",
      "INFO:__main__:0.03364500248063595, 0.02744914704423004, 0.023945095345319335, 0.02174083120253017\n",
      "INFO:__main__:0.026244142684189425, 0.04192873916855862, 0.05421335981074255, 0.06503489841627955\n",
      "INFO:__main__:0.021912493056350627, 0.020128312987699088, 0.02041794205136036, 0.020933447236403793\n",
      "INFO:__main__:0.038929977721312924, 0.04248437185352599, 0.04654241310175795, 0.05032210354604924\n",
      "INFO:__main__:Evaluation time:54.38938665390015\n",
      "INFO:__main__:Negative sampling time: 2.646014451980591s\n",
      "INFO:__main__:Epoch 141 [5.0 s]  loss=140.9648\n",
      "INFO:__main__:Negative sampling time: 2.641629934310913s\n",
      "INFO:__main__:Epoch 142 [5.0 s]  loss=140.1383\n",
      "INFO:__main__:Negative sampling time: 2.6363685131073s\n",
      "INFO:__main__:Epoch 143 [5.0 s]  loss=140.4344\n",
      "INFO:__main__:Negative sampling time: 2.6458029747009277s\n",
      "INFO:__main__:Epoch 144 [5.0 s]  loss=141.4310\n",
      "INFO:__main__:Negative sampling time: 2.6489369869232178s\n",
      "INFO:__main__:Epoch 145 [5.0 s]  loss=139.1527\n",
      "INFO:__main__:Negative sampling time: 2.676240921020508s\n",
      "INFO:__main__:Epoch 146 [5.2 s]  loss=139.8010\n",
      "INFO:__main__:Negative sampling time: 2.6475613117218018s\n",
      "INFO:__main__:Epoch 147 [5.1 s]  loss=140.3604\n",
      "INFO:__main__:Negative sampling time: 2.653837203979492s\n",
      "INFO:__main__:Epoch 148 [5.0 s]  loss=138.5350\n",
      "INFO:__main__:Negative sampling time: 2.6753971576690674s\n",
      "INFO:__main__:Epoch 149 [5.1 s]  loss=139.6884\n",
      "INFO:__main__:Negative sampling time: 2.6430273056030273s\n",
      "INFO:__main__:Epoch 150 [5.0 s]  loss=139.5655\n",
      "INFO:__main__:Negative sampling time: 2.6439454555511475s\n",
      "INFO:__main__:Epoch 151 [5.0 s]  loss=139.5376\n",
      "INFO:__main__:Negative sampling time: 2.65616512298584s\n",
      "INFO:__main__:Epoch 152 [5.0 s]  loss=138.1897\n",
      "INFO:__main__:Negative sampling time: 2.6588096618652344s\n",
      "INFO:__main__:Epoch 153 [5.0 s]  loss=138.0894\n",
      "INFO:__main__:Negative sampling time: 2.6394894123077393s\n",
      "INFO:__main__:Epoch 154 [5.0 s]  loss=138.4721\n",
      "INFO:__main__:Negative sampling time: 2.6572232246398926s\n",
      "INFO:__main__:Epoch 155 [5.0 s]  loss=139.7030\n",
      "INFO:__main__:Negative sampling time: 2.666142702102661s\n",
      "INFO:__main__:Epoch 156 [5.1 s]  loss=136.5694\n",
      "INFO:__main__:Negative sampling time: 2.6400904655456543s\n",
      "INFO:__main__:Epoch 157 [5.0 s]  loss=138.1282\n",
      "INFO:__main__:Negative sampling time: 2.6700658798217773s\n",
      "INFO:__main__:Epoch 158 [5.0 s]  loss=137.4099\n",
      "INFO:__main__:Negative sampling time: 2.662274122238159s\n",
      "INFO:__main__:Epoch 159 [5.0 s]  loss=137.9606\n",
      "INFO:__main__:Negative sampling time: 2.676734447479248s\n",
      "INFO:__main__:Epoch 160 [5.1 s]  loss=138.1816\n",
      "INFO:__main__:0.03295805823761018, 0.026849979010035663, 0.02362833772214654, 0.02148322711139564\n",
      "INFO:__main__:0.025875777646715052, 0.04098378792399725, 0.053400580364195316, 0.06417868984804116\n",
      "INFO:__main__:0.021382507092063248, 0.01965298679879935, 0.019970648075059282, 0.02048139294526026\n",
      "INFO:__main__:0.038149086531154966, 0.04159297860091052, 0.04577038419905843, 0.04954414749324716\n",
      "INFO:__main__:Evaluation time:54.65359020233154\n",
      "INFO:__main__:Negative sampling time: 2.657524824142456s\n",
      "INFO:__main__:Epoch 161 [5.0 s]  loss=137.3041\n",
      "INFO:__main__:Negative sampling time: 2.6568691730499268s\n",
      "INFO:__main__:Epoch 162 [5.1 s]  loss=136.4804\n",
      "INFO:__main__:Negative sampling time: 2.6347882747650146s\n",
      "INFO:__main__:Epoch 163 [5.1 s]  loss=136.5360\n",
      "INFO:__main__:Negative sampling time: 2.6541755199432373s\n",
      "INFO:__main__:Epoch 164 [5.0 s]  loss=136.3352\n",
      "INFO:__main__:Negative sampling time: 2.657444715499878s\n",
      "INFO:__main__:Epoch 165 [5.0 s]  loss=137.2563\n",
      "INFO:__main__:Negative sampling time: 2.6900439262390137s\n",
      "INFO:__main__:Epoch 166 [5.1 s]  loss=135.6839\n",
      "INFO:__main__:Negative sampling time: 2.6576690673828125s\n",
      "INFO:__main__:Epoch 167 [5.0 s]  loss=136.6298\n",
      "INFO:__main__:Negative sampling time: 2.6466264724731445s\n",
      "INFO:__main__:Epoch 168 [5.2 s]  loss=135.3369\n",
      "INFO:__main__:Negative sampling time: 2.645967721939087s\n",
      "INFO:__main__:Epoch 169 [5.0 s]  loss=133.9808\n",
      "INFO:__main__:Negative sampling time: 2.6465680599212646s\n",
      "INFO:__main__:Epoch 170 [5.0 s]  loss=135.8076\n",
      "INFO:__main__:Negative sampling time: 2.6492695808410645s\n",
      "INFO:__main__:Epoch 171 [5.0 s]  loss=136.7698\n",
      "INFO:__main__:Negative sampling time: 2.6537318229675293s\n",
      "INFO:__main__:Epoch 172 [5.0 s]  loss=135.5068\n",
      "INFO:__main__:Negative sampling time: 2.6714518070220947s\n",
      "INFO:__main__:Epoch 173 [5.1 s]  loss=134.5601\n",
      "INFO:__main__:Negative sampling time: 2.6761398315429688s\n",
      "INFO:__main__:Epoch 174 [5.1 s]  loss=134.4728\n",
      "INFO:__main__:Negative sampling time: 2.6646876335144043s\n",
      "INFO:__main__:Epoch 175 [5.0 s]  loss=134.0894\n",
      "INFO:__main__:Negative sampling time: 2.657872438430786s\n",
      "INFO:__main__:Epoch 176 [5.0 s]  loss=134.9661\n",
      "INFO:__main__:Negative sampling time: 2.6414785385131836s\n",
      "INFO:__main__:Epoch 177 [5.0 s]  loss=135.1417\n",
      "INFO:__main__:Negative sampling time: 2.698110580444336s\n",
      "INFO:__main__:Epoch 178 [5.1 s]  loss=136.4983\n",
      "INFO:__main__:Negative sampling time: 2.645721435546875s\n",
      "INFO:__main__:Epoch 179 [5.0 s]  loss=135.0315\n",
      "INFO:__main__:Negative sampling time: 2.6457629203796387s\n",
      "INFO:__main__:Epoch 180 [5.0 s]  loss=134.7699\n",
      "INFO:__main__:0.032851200244250665, 0.02702171507079206, 0.02373010723963182, 0.021587222837075815\n",
      "INFO:__main__:0.025706293705701065, 0.04127780532315291, 0.05380961822688658, 0.06472891921846415\n",
      "INFO:__main__:0.021345000784473364, 0.019642373541735075, 0.019976927468813237, 0.020496912567030737\n",
      "INFO:__main__:0.03804823879223616, 0.04172847031332692, 0.045923354833825765, 0.04974404343167132\n",
      "INFO:__main__:Evaluation time:54.23179244995117\n",
      "INFO:__main__:Negative sampling time: 2.6679656505584717s\n",
      "INFO:__main__:Epoch 181 [5.0 s]  loss=134.6335\n",
      "INFO:__main__:Negative sampling time: 2.6432723999023438s\n",
      "INFO:__main__:Epoch 182 [5.0 s]  loss=134.2910\n",
      "INFO:__main__:Negative sampling time: 2.6415131092071533s\n",
      "INFO:__main__:Epoch 183 [5.0 s]  loss=136.4306\n",
      "INFO:__main__:Negative sampling time: 2.6597886085510254s\n",
      "INFO:__main__:Epoch 184 [5.0 s]  loss=134.3872\n",
      "INFO:__main__:Negative sampling time: 2.6522698402404785s\n",
      "INFO:__main__:Epoch 185 [5.0 s]  loss=135.0880\n",
      "INFO:__main__:Negative sampling time: 2.6795780658721924s\n",
      "INFO:__main__:Epoch 186 [5.1 s]  loss=134.5302\n",
      "INFO:__main__:Negative sampling time: 2.659583568572998s\n",
      "INFO:__main__:Epoch 187 [5.0 s]  loss=132.4193\n",
      "INFO:__main__:Negative sampling time: 2.662447214126587s\n",
      "INFO:__main__:Epoch 188 [5.0 s]  loss=132.4121\n",
      "INFO:__main__:Negative sampling time: 2.642404556274414s\n",
      "INFO:__main__:Epoch 189 [5.0 s]  loss=134.1546\n",
      "INFO:__main__:Negative sampling time: 2.641242027282715s\n",
      "INFO:__main__:Epoch 190 [5.0 s]  loss=133.1083\n",
      "INFO:__main__:Negative sampling time: 2.6620113849639893s\n",
      "INFO:__main__:Epoch 191 [5.1 s]  loss=133.9312\n",
      "INFO:__main__:Negative sampling time: 2.672736167907715s\n",
      "INFO:__main__:Epoch 192 [5.1 s]  loss=133.5095\n",
      "INFO:__main__:Negative sampling time: 2.649914264678955s\n",
      "INFO:__main__:Epoch 193 [5.0 s]  loss=133.6856\n",
      "INFO:__main__:Negative sampling time: 2.6394505500793457s\n",
      "INFO:__main__:Epoch 194 [5.0 s]  loss=133.4452\n",
      "INFO:__main__:Negative sampling time: 2.6477205753326416s\n",
      "INFO:__main__:Epoch 195 [5.1 s]  loss=133.4133\n",
      "INFO:__main__:Negative sampling time: 2.6503148078918457s\n",
      "INFO:__main__:Epoch 196 [5.1 s]  loss=133.0177\n",
      "INFO:__main__:Negative sampling time: 2.6880364418029785s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Epoch 197 [5.2 s]  loss=132.4480\n",
      "INFO:__main__:Negative sampling time: 2.674652099609375s\n",
      "INFO:__main__:Epoch 198 [5.1 s]  loss=130.5391\n",
      "INFO:__main__:Negative sampling time: 2.6838295459747314s\n",
      "INFO:__main__:Epoch 199 [5.1 s]  loss=132.8796\n",
      "INFO:__main__:Negative sampling time: 2.6383986473083496s\n",
      "INFO:__main__:Epoch 200 [5.0 s]  loss=131.9096\n",
      "INFO:__main__:0.03278632217685376, 0.026834713582412916, 0.023741556310348917, 0.021525207037358357\n",
      "INFO:__main__:0.025383422157371556, 0.04100906978691678, 0.05372274956175477, 0.06468087952691108\n",
      "INFO:__main__:0.021166474788722238, 0.019471343769026195, 0.019844211193125384, 0.020363019740075226\n",
      "INFO:__main__:0.037800672014348745, 0.04142955992020102, 0.045767426863562506, 0.04956457057290633\n",
      "INFO:__main__:Evaluation time:54.26233267784119\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train = Interactions(train_val_set, num_users, num_items)\n",
    "train.to_sequence(config.L, config.T)\n",
    "\n",
    "logger.info(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "logger.info(config)\n",
    "train_model(train, test_set, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
